<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>dev on @jeqo</title>
    <link>https://jeqo.github.io/categories/dev/</link>
    <description>Recent content in dev on @jeqo</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; Copyright @jeqo</copyright>
    <lastBuildDate>Wed, 24 Aug 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://jeqo.github.io/categories/dev/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Piggyback on Kafka Connect Schemas to process Kafka records in a generic way</title>
      <link>https://jeqo.github.io/til/kafka-connect-schema-serde/</link>
      <pubDate>Wed, 24 Aug 2022 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/til/kafka-connect-schema-serde/</guid>
      <description>When reading from/writing to Kafka topics, a serializer/deserializer (a.k.a SerDes) is needed to process record key and value bytes. Specific SerDes that turn bytes into specific objects (e.g. POJO) are used, unless a generic JSON object or Avro structure is used.
Kafka Connect has to deal with generic structures to apply message transformations and convert messages from external sources into Kafka records and vice-versa. It has a SchemaAndValue composed type that includes a Connect Schema type derived from Schema Registry or JSON Schema included in the payload, and a value object.</description>
    </item>
    
    <item>
      <title>Kafka Streams: Tick stream-time with control messages</title>
      <link>https://jeqo.github.io/posts/2022-06-17-kafka-streams-tick-event-time-with-control-messages/</link>
      <pubDate>Fri, 17 Jun 2022 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/posts/2022-06-17-kafka-streams-tick-event-time-with-control-messages/</guid>
      <description>&lt;p&gt;Kafka Streams is in many ways governed by the concept of time.
For instance, as soon as stateful operations are used, the event-time drives how events are grouped, joined, and emitted.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://developer.confluent.io/learn-kafka/kafka-streams/time-concepts/#stream-time&#34;&gt;Stream-time&lt;/a&gt;
is the concept within Kafka Streams representing the largest timestamp seen by the the stream application (per-partition).
In comparison with wall-clock time (i.e. system time) — at the execution of an application — stream-time is driven by the data seen by the application.
This ensures that the results produced by a Kafka Streams application are reproducible.&lt;/p&gt;
&lt;p&gt;One nuance of stream-time is that it &lt;em&gt;needs&lt;/em&gt; incoming events to &amp;ldquo;tick&amp;rdquo;.
This could represent an issue for events that are sparse in time, and we expect results to be produced more often (e.g. windows to be closed and emit, punctiation to be calculated).&lt;/p&gt;
&lt;p&gt;This is a known issue, and there are some proposals to overcome it in certain parts of the framework,
e.g. &lt;a href=&#34;https://cwiki.apache.org/confluence/display/KAFKA/KIP-424%3A+Allow+suppression+of+intermediate+events+based+on+wall+clock+time&#34;&gt;KIP-424&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This post covers a proof-of-concept instrumenting producers to emit contol messages to advance stream time.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Explore Kafka data with kcat, sqlite, and Datasette</title>
      <link>https://jeqo.github.io/til/2022-03-10-kcat-end-offset-and-datasette/</link>
      <pubDate>Thu, 10 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/til/2022-03-10-kcat-end-offset-and-datasette/</guid>
      <description>&lt;p&gt;I have been playing with Datasette and sqlite for a bit, trying to collect and expose data efficiently for others to analyze.
Recently started finding use-cases to get data from Apache Kafka, and expose it quickly to analyze it.
Why not using Datasette?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Releasing OS-specific GraalVM native image binaries easier with JReleaser</title>
      <link>https://jeqo.github.io/til/2022-03-01-jreleaser-graalvm-native-image/</link>
      <pubDate>Tue, 01 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/til/2022-03-01-jreleaser-graalvm-native-image/</guid>
      <description>&lt;p&gt;Packaging and releasing Java applications (e.g. CLI) tend to be cumbersome, and the user-experience tended not to be the best as users have to download a valid version of JRE, etc.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Changing void returning type in Java methods breaks binary compatibility</title>
      <link>https://jeqo.github.io/til/2022-02-16-java-void-binary-compatibility/</link>
      <pubDate>Wed, 16 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/til/2022-02-16-java-void-binary-compatibility/</guid>
      <description>&lt;p&gt;While &lt;a href=&#34;https://cwiki.apache.org/confluence/display/KAFKA/KIP-820%3A+Extend+KStream+process+with+new+Processor+API&#34;&gt;proposing changes to Kafka Streams DSL&lt;/a&gt;, I propose changing the return type of one method from &lt;code&gt;void&lt;/code&gt; to &lt;code&gt;KStream&amp;lt;KOut, VOut&lt;/code&gt;.
I was under the (wrong) impression that this change wouldn&amp;rsquo;t affect users.
I was also not considering that applications might just drop a new library without recompiling their application.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Kafka Streams FK-join within the same KTable</title>
      <link>https://jeqo.github.io/til/2022-01-29-kafka-streams-fk-join-same-table/</link>
      <pubDate>Sat, 29 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/til/2022-01-29-kafka-streams-fk-join-same-table/</guid>
      <description>&lt;p&gt;KTable to KTable foreign-key joins is one of the coolest features in Kafka Streams.&lt;/p&gt;
&lt;p&gt;I was wondering whether this feature would handle FK-joins between values on the same table.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Kafka Streams abstracts access to multiple tasks state stores when reading</title>
      <link>https://jeqo.github.io/til/2022-01-26-kafka-streams-iq-composite/</link>
      <pubDate>Wed, 26 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/til/2022-01-26-kafka-streams-iq-composite/</guid>
      <description>&lt;p&gt;Kafka Streams applications could scale either horizontally (add more instances) or vertically (add more threads).
When scaled vertically, multiple tasks store multiple partitions locally.
An interesting question is whether Kafka Streams gives access when reading (i.e. &lt;a href=&#34;https://docs.confluent.io/platform/current/streams/developer-guide/interactive-queries.html&#34;&gt;Interactive Queries&lt;/a&gt;) to these stores, and how does it manage to abstract the access to different stores managed by multiple tasks.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
