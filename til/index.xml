<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Tils on @jeqo</title>
    <link>https://jeqo.github.io/til/</link>
    <description>Recent content in Tils on @jeqo</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; Copyright @jeqo</copyright>
    <lastBuildDate>Tue, 01 Mar 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://jeqo.github.io/til/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Using JReleaser to release GraalVM native images</title>
      <link>https://jeqo.github.io/til/2022-03-01-jreleaser-graalvm-native-image/</link>
      <pubDate>Tue, 01 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/til/2022-03-01-jreleaser-graalvm-native-image/</guid>
      <description>Packaging and releasing Java applications (e.g. CLI) tend to be cumbersome, and the user-experience tended not to be the best as users have to download a valid version of JRE, etc.
JReleaser is an awesome tool that takes most of the heavy-lifting — including, but not limited, to packaging, distribution, notifications, etc. — and let you focus on your application details.
Today, I found a great example of how to use JReleaser and mixing it with GraalVM to package native-image applications and releasing them on GitHub: https://github.</description>
    </item>
    
    <item>
      <title>Changing void returning type in Java methods breaks binary compatibility</title>
      <link>https://jeqo.github.io/til/2022-02-16-java-void-binary-compatibility/</link>
      <pubDate>Wed, 16 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/til/2022-02-16-java-void-binary-compatibility/</guid>
      <description>While proposing changes to Kafka Streams DSL, I propose changing the return type of one method from void to KStream&amp;lt;KOut, VOut. I was under the (wrong) impression that this change wouldn&amp;rsquo;t affect users. I was also not considering that applications might just drop a new library without recompiling their application.
This change is what is known as source compatible but not binary compatible — meaning the user will need to recompile their application.</description>
    </item>
    
    <item>
      <title>Enable Certificate Revocation on Kafka clusters</title>
      <link>https://jeqo.github.io/til/2022-02-09-kafka-ssl-crl/</link>
      <pubDate>Wed, 09 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/til/2022-02-09-kafka-ssl-crl/</guid>
      <description>&lt;p&gt;Recently I got a question on how to manage revoked SSL certificates in Kafka clusters.
With a proper Public Key Infrastructure, a Certificate Revocation List (CRL) can be available for clients to validate if a certificate is still valid regardless of its time-to-live.
For instance, if a private key has been compromised, then a certificate can be revoked before it&amp;rsquo;s valid date.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Kafka Streams FK-join within the same KTable</title>
      <link>https://jeqo.github.io/til/2022-01-29-kafka-streams-fk-join-same-table/</link>
      <pubDate>Sat, 29 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/til/2022-01-29-kafka-streams-fk-join-same-table/</guid>
      <description>&lt;p&gt;KTable to KTable foreign-key joins is one of the coolest features in Kafka Streams.&lt;/p&gt;
&lt;p&gt;I was wondering whether this feature would handle FK-joins between values on the same table.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Kafka Streams abstracts access to multiple tasks state stores when reading</title>
      <link>https://jeqo.github.io/til/2022-01-26-kafka-streams-iq-composite/</link>
      <pubDate>Wed, 26 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/til/2022-01-26-kafka-streams-iq-composite/</guid>
      <description>&lt;p&gt;Kafka Streams applications could scale either horizontally (add more instances) or vertically (add more threads).
When scaled vertically, multiple tasks store multiple partitions locally.
An interesting question is whether Kafka Streams gives access when reading (i.e. &lt;a href=&#34;https://docs.confluent.io/platform/current/streams/developer-guide/interactive-queries.html&#34;&gt;Interactive Queries&lt;/a&gt;) to these stores, and how does it manage to abstract the access to different stores managed by multiple tasks.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>reload4j as drop-in replacement for log4j 1.x</title>
      <link>https://jeqo.github.io/til/2022-01-25-reload4j/</link>
      <pubDate>Tue, 25 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/til/2022-01-25-reload4j/</guid>
      <description>&lt;p&gt;TIL there is a drop-in replacement for log4j 1.x: &lt;a href=&#34;https://reload4j.qos.ch/&#34;&gt;Reload4j&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Ansible has a debug mode to pause and troubleshoot</title>
      <link>https://jeqo.github.io/til/2022-01-21-ansible-debug/</link>
      <pubDate>Fri, 21 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/til/2022-01-21-ansible-debug/</guid>
      <description>&lt;p&gt;I have been running Ansible for a while now.
My usual/naive way of debugging has always been adding a &lt;code&gt;debug&lt;/code&gt; module&lt;a href=&#34;https://docs.ansible.com/ansible/latest/collections/ansible/builtin/debug_module.html&#34;&gt;[1]&lt;/a&gt;, and get the execution running til that point.&lt;/p&gt;
&lt;p&gt;I figured that there are better ways to deal with this&lt;a href=&#34;https://docs.ansible.com/ansible/2.9/user_guide/playbooks_debugger.html#examples&#34;&gt;[2]&lt;/a&gt;.
By using the debug mode, tasks will stop when failing (by default) and you&amp;rsquo;ll be able to introspect into the task, variables, and context when things failed.
Even better, you&amp;rsquo;ll be able to re-execute if there was a transient error.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Changing Kafka Broker&#39;s rack</title>
      <link>https://jeqo.github.io/til/2021-12-10-kafka-change-rack/</link>
      <pubDate>Fri, 10 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/til/2021-12-10-kafka-change-rack/</guid>
      <description>&lt;p&gt;Kafka broker configuration includes a &lt;code&gt;rack&lt;/code&gt; label to define the location of the broker.
This is useful when placing replicas across the cluster to ensure replicas are spread across locations &lt;em&gt;as evenly as possible&lt;/em&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Kafka Producer idempotency is enabled by default since 3.0</title>
      <link>https://jeqo.github.io/til/2021-12-09-kafka-v3-idempotent-acks-all/</link>
      <pubDate>Thu, 09 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/til/2021-12-09-kafka-v3-idempotent-acks-all/</guid>
      <description>Since Apache Kafka 3.0, Producers come with enable.idempotency=true which leads to acks=all, along with other changes enforced by idempotency.
This means by default Producers will be balanced between latency (no batching) and durability — different from previous versions where the main goal was to reduce latency even by risking durability with acks=1.</description>
    </item>
    
    <item>
      <title>Reducing `acks` doesn&#39;t help to reduce end-to-end latency</title>
      <link>https://jeqo.github.io/til/2021-12-09-kafka-reducing-acks-and-latency/</link>
      <pubDate>Thu, 09 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/til/2021-12-09-kafka-reducing-acks-and-latency/</guid>
      <description>&lt;p&gt;Kafka Producers enforce durability across replicas by setting &lt;code&gt;acks=all&lt;/code&gt; (&lt;a href=&#34;https://jeqo.github.io/til/kafka-v3-idea&#34;&gt;default since v3.0&lt;/a&gt;).
As enforcing this guarantee requires waiting for replicas to sync, this increases latency; and reducing it tends to give the impression that latency gets reduced overall.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Use min.insync.replicas for fault-tolerance</title>
      <link>https://jeqo.github.io/til/2021-12-02-kafka-min-isr/</link>
      <pubDate>Thu, 02 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/til/2021-12-02-kafka-min-isr/</guid>
      <description>&lt;p&gt;Things to remember:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Topic replication factor is not enough to guarantee fault-tolerance. If &lt;code&gt;min.insync.replicas&lt;/code&gt; is not defined i.e. 1, then data could potentially be lost.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;acks=all&lt;/code&gt; will force replica leader to wait for &lt;em&gt;all&lt;/em&gt; brokers in the ISR, not only the &lt;code&gt;min.insync.replicas&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;If replicas available are equal to minimum ISR, then the topic partitions are at the edge of losing availability. If one broker becomes unavailable (e.g. restarting), then producers will fail to write data.&lt;/li&gt;
&lt;li&gt;Topic configuration is inherited from the server. If broker configuration changes, it affects the &lt;em&gt;existing&lt;/em&gt; topics. Keep the topic defaults, unless it needs to be different than broker default for easier maintenance.&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>About TILs</title>
      <link>https://jeqo.github.io/til/2021-12-01-about-til/</link>
      <pubDate>Wed, 01 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/til/2021-12-01-about-til/</guid>
      <description>Today I learned about Today-I-Learned posts from Simon Willison: https://til.simonwillison.net/ and found it super cool, so I decided to try out, let&amp;rsquo;s see how it goes.</description>
    </item>
    
  </channel>
</rss>
