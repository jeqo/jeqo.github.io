<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0">
    <channel>
        <title>Jorge Quilcate Otoya on @jeqo</title>
        <generator uri="https://gohugo.io">Hugo</generator>
        <link>https://jeqo.github.io/es/categories/integration/</link>
        <language>en-us</language>
        <author>Jorge Quilcate Otoya</author>
        
        <updated>Thu, 16 Feb 2017 00:00:00 UTC</updated>
        
        <item>
            <title>De Mensajería a Log de Eventos con Apache Kafka - Perú JUG</title>
            <link>https://jeqo.github.io/es/talk/de-mensajeria-a-log-de-eventos-perujug/</link>
            <pubDate>Thu, 16 Feb 2017 00:00:00 UTC</pubDate>
            <author>Jorge Quilcate Otoya</author>
            <guid>https://jeqo.github.io/es/talk/de-mensajeria-a-log-de-eventos-perujug/</guid>
            <description>&lt;p&gt;Presentado al &lt;a href=&#34;https://twitter.com/perujug/&#34;&gt;Perú JUG&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h1 id=&#34;video&#34;&gt;Video&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://youtu.be/gZCzD5bCdBA&#34;&gt;Hangout&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;diapositivas&#34;&gt;Diapositivas&lt;/h1&gt;

&lt;script async class=&#34;speakerdeck-embed&#34; data-id=&#34;a0a61a9ec75f4a8c9a49b5756b1f5f80&#34; data-ratio=&#34;1.33333333333333&#34; src=&#34;//speakerdeck.com/assets/embed.js&#34;&gt;&lt;/script&gt;


&lt;h1 id=&#34;código-fuente&#34;&gt;Código Fuente&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/jeqo/talk-kafka-messaging-logs&#34;&gt;https://github.com/jeqo/talk-kafka-messaging-logs&lt;/a&gt;&lt;/p&gt;</description>
        </item>
        
        <item>
            <title>Kafka - Retroceder Offsets de Consumidores</title>
            <link>https://jeqo.github.io/es/post/2017-01-31-kafka-rewind-consumers-offset/</link>
            <pubDate>Tue, 31 Jan 2017 00:00:00 UTC</pubDate>
            <author>Jorge Quilcate Otoya</author>
            <guid>https://jeqo.github.io/es/post/2017-01-31-kafka-rewind-consumers-offset/</guid>
            <description>&lt;p&gt;Una de las características más importantes de &lt;em&gt;Apache Kafka&lt;/em&gt; es el manejo
de múltiples consumidores. Cada &lt;code&gt;consumer group&lt;/code&gt; tiene un &lt;code&gt;offset&lt;/code&gt;, que
determina hasta que punto del &lt;code&gt;topic&lt;/code&gt; se encuentra consumido por &lt;code&gt;consumer group&lt;/code&gt;.
Así, cada &lt;code&gt;consumer group&lt;/code&gt; puede manejar los &lt;code&gt;offset&lt;/code&gt; independientemente, por
partición.&lt;/p&gt;

&lt;p&gt;Esto ofrece la posibilidad de retroceder en el tiempo y reprocesar mensaje desde
el inicio de un &lt;code&gt;topic&lt;/code&gt; y regenerar el estado actual del sistema.&lt;/p&gt;

&lt;p&gt;Pero, cómo realizar esto de forma programática?&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Código fuente: &lt;a href=&#34;https://github.com/jeqo/post-kafka-rewind-consumer-offset&#34;&gt;https://github.com/jeqo/post-kafka-rewind-consumer-offset&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;conceptos-básicos&#34;&gt;Conceptos Básicos&lt;/h2&gt;

&lt;h3 id=&#34;topics-y-offsets&#34;&gt;Topics y Offsets&lt;/h3&gt;

&lt;p&gt;Lo primero por entender para lograr retroceder los consumidores en Kafka es:
retroceder sobre qué? Cada &lt;code&gt;topic&lt;/code&gt; esta dividido en &lt;code&gt;partitions&lt;/code&gt;. Los
registros enviados por los &lt;code&gt;Producers&lt;/code&gt; son balanceados entre las &lt;code&gt;partitions&lt;/code&gt;,
así cada partición tiene su propio índice de &lt;code&gt;offsets&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Cada &lt;code&gt;record&lt;/code&gt; tiene un &lt;code&gt;offset&lt;/code&gt; asignado que será usado por los &lt;code&gt;consumers&lt;/code&gt;
para definir qué mensajes han sido consumidos del &lt;strong&gt;log&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 id=&#34;consumers-y-consumer-groups&#34;&gt;Consumers y Consumer Groups&lt;/h3&gt;

&lt;p&gt;Una vez entendido que los &lt;code&gt;topics&lt;/code&gt; tienen &lt;code&gt;partitions&lt;/code&gt; y &lt;code&gt;offsets&lt;/code&gt; por &lt;code&gt;partition&lt;/code&gt;
podemos pasar a definir como trabajan los &lt;code&gt;consumers&lt;/code&gt; y &lt;code&gt;consumer groups&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;Consumers&lt;/code&gt; están agrupados por &lt;code&gt;group.id&lt;/code&gt;. Ésta propiedad identifica a cada&lt;br /&gt;
&lt;code&gt;consumer group&lt;/code&gt;, así el &lt;code&gt;broker&lt;/code&gt; conoce cúal fue el último &lt;code&gt;record&lt;/code&gt; consumido
por &lt;code&gt;offset&lt;/code&gt;, por &lt;code&gt;partition&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Antes de continuar, revisemos la clase que funcionará como un &lt;code&gt;Kafka Consumer&lt;/code&gt;
simple implementado en Java:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;KafkaSimpleProducer.java&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #f8f8f8&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;public&lt;/span&gt; &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;static&lt;/span&gt; &lt;span style=&#34;color: #B00040&#34;&gt;void&lt;/span&gt; &lt;span style=&#34;color: #0000FF&#34;&gt;main&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;(&lt;/span&gt;String&lt;span style=&#34;color: #666666&#34;&gt;[]&lt;/span&gt; args&lt;span style=&#34;color: #666666&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color: #666666&#34;&gt;{&lt;/span&gt;
    &lt;span style=&#34;color: #666666&#34;&gt;...&lt;/span&gt;
    Properties properties &lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;new&lt;/span&gt; Properties&lt;span style=&#34;color: #666666&#34;&gt;();&lt;/span&gt;
    properties&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #7D9029&#34;&gt;put&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;(&lt;/span&gt;ProducerConfig&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #7D9029&#34;&gt;BOOTSTRAP_SERVERS_CONFIG&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;,&lt;/span&gt; bootstrapServers&lt;span style=&#34;color: #666666&#34;&gt;);&lt;/span&gt;
    properties&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #7D9029&#34;&gt;put&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;(&lt;/span&gt;ProducerConfig&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #7D9029&#34;&gt;KEY_SERIALIZER_CLASS_CONFIG&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;,&lt;/span&gt; StringSerializer&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #7D9029&#34;&gt;class&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #7D9029&#34;&gt;getName&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;());&lt;/span&gt;
    properties&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #7D9029&#34;&gt;put&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;(&lt;/span&gt;ProducerConfig&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #7D9029&#34;&gt;VALUE_SERIALIZER_CLASS_CONFIG&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;,&lt;/span&gt; StringSerializer&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #7D9029&#34;&gt;class&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #7D9029&#34;&gt;getName&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;());&lt;/span&gt;

    Producer&lt;span style=&#34;color: #666666&#34;&gt;&amp;lt;&lt;/span&gt;String&lt;span style=&#34;color: #666666&#34;&gt;,&lt;/span&gt; String&lt;span style=&#34;color: #666666&#34;&gt;&amp;gt;&lt;/span&gt; producer &lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;new&lt;/span&gt; KafkaProducer&lt;span style=&#34;color: #666666&#34;&gt;&amp;lt;&amp;gt;(&lt;/span&gt;properties&lt;span style=&#34;color: #666666&#34;&gt;);&lt;/span&gt;

    IntStream&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #7D9029&#34;&gt;rangeClosed&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;(1,&lt;/span&gt; &lt;span style=&#34;color: #666666&#34;&gt;100)&lt;/span&gt;
            &lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #7D9029&#34;&gt;boxed&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;()&lt;/span&gt;
            &lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #7D9029&#34;&gt;map&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;(&lt;/span&gt;number &lt;span style=&#34;color: #666666&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;new&lt;/span&gt; ProducerRecord&lt;span style=&#34;color: #666666&#34;&gt;&amp;lt;&amp;gt;(&lt;/span&gt;
                    &lt;span style=&#34;color: #BA2121&#34;&gt;&amp;quot;topic-1&amp;quot;&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;,&lt;/span&gt;
                    number&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #7D9029&#34;&gt;toString&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;(),&lt;/span&gt;
                    number&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #7D9029&#34;&gt;toString&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;()))&lt;/span&gt;
            &lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #7D9029&#34;&gt;map&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;(&lt;/span&gt;record &lt;span style=&#34;color: #666666&#34;&gt;-&amp;gt;&lt;/span&gt; producer&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #7D9029&#34;&gt;send&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;(&lt;/span&gt;record&lt;span style=&#34;color: #666666&#34;&gt;))&lt;/span&gt;
            &lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #7D9029&#34;&gt;forEach&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;(&lt;/span&gt;result &lt;span style=&#34;color: #666666&#34;&gt;-&amp;gt;&lt;/span&gt; printMetadata&lt;span style=&#34;color: #666666&#34;&gt;(&lt;/span&gt;result&lt;span style=&#34;color: #666666&#34;&gt;));&lt;/span&gt;
    producer&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #7D9029&#34;&gt;close&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;();&lt;/span&gt;
&lt;span style=&#34;color: #666666&#34;&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Este &lt;code&gt;producer&lt;/code&gt; creará 100 &lt;code&gt;records&lt;/code&gt; en el topic &lt;code&gt;topic-1&lt;/code&gt;, con &lt;code&gt;offsets&lt;/code&gt;
de &lt;code&gt;0&lt;/code&gt; a &lt;code&gt;99&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&#34;desde-línea-de-comandos&#34;&gt;Desde Línea de Comandos&lt;/h2&gt;

&lt;p&gt;En este primer escenario revisaremos como manejar los offsets de &lt;code&gt;consumers&lt;/code&gt;
desde &lt;em&gt;línea de comandos&lt;/em&gt;, para tener una idea de como implementarlo en
nuestra aplicación.&lt;/p&gt;

&lt;p&gt;Cuando trabajas desde un terminal, si se puede utilizar &lt;code&gt;kafka-console-consumer&lt;/code&gt;
sin &lt;code&gt;group.id&lt;/code&gt; definido, un nuevo &lt;code&gt;group.id&lt;/code&gt; es generado internamente:
&lt;code&gt;console-consumer-${new Random().nextInt(100000)}&lt;/code&gt;.
Así que a menos que se utilize el mismo &lt;code&gt;group.id&lt;/code&gt; luego, será como si
creara un nuevo &lt;code&gt;consumer group&lt;/code&gt; cada vez que se inice un terminal con
&lt;code&gt;kafka-console-consumer&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Por defecto, cuando se conecta a un &lt;code&gt;topic&lt;/code&gt; como un &lt;code&gt;consumer&lt;/code&gt; se inicia con
el &lt;em&gt;último&lt;/em&gt; &lt;code&gt;offset&lt;/code&gt;, así que no se recibirán nuevos &lt;code&gt;records&lt;/code&gt; a menos que nuevos
mensajes arriben luego de iniciada la conexión.&lt;/p&gt;

&lt;p&gt;En este caso, para ir hacia el inicio del topic sería suficiente con agregar
la opción &lt;code&gt;--from-beginning&lt;/code&gt; a la línea de comandos:&lt;/p&gt;

&lt;script type=&#34;text/javascript&#34; src=&#34;https://asciinema.org/a/101246.js&#34; id=&#34;asciicast-101246&#34; async&gt;&lt;/script&gt;

&lt;p&gt;Pero, qué pasaría si se usa la propiedad &lt;code&gt;group.id&lt;/code&gt;?, La ópcion &lt;code&gt;--from-beginning&lt;/code&gt;
solo funcionaría la primera vez, ya que el &lt;code&gt;offset&lt;/code&gt; sería registrado en el clúster::&lt;/p&gt;

&lt;script type=&#34;text/javascript&#34; src=&#34;https://asciinema.org/a/101248.js&#34; id=&#34;asciicast-101248&#34; async&gt;&lt;/script&gt;

&lt;script type=&#34;text/javascript&#34; src=&#34;https://asciinema.org/a/101250.js&#34; id=&#34;asciicast-101250&#34; async&gt;&lt;/script&gt;

&lt;p&gt;Así que, cómo se regresaría al inicio del log en este caso?&lt;/p&gt;

&lt;p&gt;Podemos usar la opción &lt;code&gt;--offset&lt;/code&gt; con estas tres alternativas:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;--offset &amp;lt;String: consume offset&amp;gt;        The offset id to consume from (a non-  
                                           negative number), or &#39;earliest&#39;      
                                           which means from beginning, or       
                                           &#39;latest&#39; which means from end        
                                           (default: latest)
&lt;/code&gt;&lt;/pre&gt;

&lt;script type=&#34;text/javascript&#34; src=&#34;https://asciinema.org/a/101252.js&#34; id=&#34;asciicast-101252&#34; async&gt;&lt;/script&gt;

&lt;h2 id=&#34;desde-clientes-java&#34;&gt;Desde Clientes Java&lt;/h2&gt;

&lt;p&gt;Ahora, luego de ver que desde la línea de comandos en sencillo regresar en el
tiempo sobre el log; pero, cómo hacer éstas operaciones desde una aplicación?&lt;/p&gt;

&lt;p&gt;Si estás utilizando Kafka Consumers en tu aplicación, tienes las siguientes
opciones (con Java):&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://kafka.apache.org/documentation/#consumerapi&#34;&gt;Kafka Consumer API&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://kafka.apache.org/documentation/#streamsapi&#34;&gt;Kafka Streams API&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Haciendo la historia corta: Si necesitas capacidades de procesar mensajes
desde Kafka de forma &lt;em&gt;stateful&lt;/em&gt; (manteniendo el estado), es recomendable
utilizar &lt;code&gt;Kafka Streams API&lt;/code&gt;.
Si necesitas una API simple para consumir mensajes uno a uno, utiliza
&lt;code&gt;Kafka Consumer API&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Al momento de escribir este post, éstas son las opciones para hacer &lt;em&gt;rewind&lt;/em&gt;
de &lt;code&gt;offsets&lt;/code&gt; desde estas APIs:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;Kafka Consumer API&lt;/code&gt; soporta regresar al &lt;em&gt;inicio&lt;/em&gt; de topic, ir a un
&lt;code&gt;offset&lt;/code&gt; específico, o regresar a un punto en el tiempo (timestamp).&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;Kafka Streams API&lt;/code&gt; en este momemnto solo soporta regresar al &lt;code&gt;offset&lt;/code&gt; inicial
de los &lt;code&gt;input topics&lt;/code&gt;, y se encuentra bien explicado por &lt;a href=&#34;https://github.com/mjsax&#34;&gt;Matthias J. Sax&lt;/a&gt;
en su post:
&lt;a href=&#34;https://www.confluent.io/blog/data-reprocessing-with-kafka-streams-resetting-a-streams-application/&#34;&gt;[1]&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Así que me enfocaré en las opciones disponibles desde el API de &lt;code&gt;Kafka Consumer&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Un consumidor simple luciría así:&lt;/p&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #f8f8f8&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;public&lt;/span&gt; &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;static&lt;/span&gt; &lt;span style=&#34;color: #B00040&#34;&gt;void&lt;/span&gt; &lt;span style=&#34;color: #0000FF&#34;&gt;main&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;(&lt;/span&gt;String&lt;span style=&#34;color: #666666&#34;&gt;[]&lt;/span&gt; args&lt;span style=&#34;color: #666666&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color: #666666&#34;&gt;{&lt;/span&gt;
    Properties props &lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;new&lt;/span&gt; Properties&lt;span style=&#34;color: #666666&#34;&gt;();&lt;/span&gt;
    props&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #7D9029&#34;&gt;put&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;(&lt;/span&gt;ConsumerConfig&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #7D9029&#34;&gt;BOOTSTRAP_SERVERS_CONFIG&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;,&lt;/span&gt; bootstrapServers&lt;span style=&#34;color: #666666&#34;&gt;);&lt;/span&gt;
    props&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #7D9029&#34;&gt;put&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;(&lt;/span&gt;ConsumerConfig&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #7D9029&#34;&gt;GROUP_ID_CONFIG&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #BA2121&#34;&gt;&amp;quot;test&amp;quot;&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;);&lt;/span&gt;
    props&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #7D9029&#34;&gt;put&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;(&lt;/span&gt;ConsumerConfig&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #7D9029&#34;&gt;ENABLE_AUTO_COMMIT_CONFIG&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #BA2121&#34;&gt;&amp;quot;true&amp;quot;&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;);&lt;/span&gt;
    props&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #7D9029&#34;&gt;put&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;(&lt;/span&gt;ConsumerConfig&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #7D9029&#34;&gt;KEY_DESERIALIZER_CLASS_CONFIG&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #BA2121&#34;&gt;&amp;quot;org.apache.kafka.common.serialization.StringDeserializer&amp;quot;&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;);&lt;/span&gt;
    props&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #7D9029&#34;&gt;put&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;(&lt;/span&gt;ConsumerConfig&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #7D9029&#34;&gt;VALUE_DESERIALIZER_CLASS_CONFIG&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #BA2121&#34;&gt;&amp;quot;org.apache.kafka.common.serialization.StringDeserializer&amp;quot;&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;);&lt;/span&gt;

    KafkaConsumer&lt;span style=&#34;color: #666666&#34;&gt;&amp;lt;&lt;/span&gt;String&lt;span style=&#34;color: #666666&#34;&gt;,&lt;/span&gt; String&lt;span style=&#34;color: #666666&#34;&gt;&amp;gt;&lt;/span&gt; consumer &lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;new&lt;/span&gt; KafkaConsumer&lt;span style=&#34;color: #666666&#34;&gt;&amp;lt;&amp;gt;(&lt;/span&gt;props&lt;span style=&#34;color: #666666&#34;&gt;);&lt;/span&gt;
    consumer&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #7D9029&#34;&gt;subscribe&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;(&lt;/span&gt;Arrays&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #7D9029&#34;&gt;asList&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;quot;topic-1&amp;quot;&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;));&lt;/span&gt;

    &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;while&lt;/span&gt; &lt;span style=&#34;color: #666666&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;true&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color: #666666&#34;&gt;{&lt;/span&gt;
        ConsumerRecords&lt;span style=&#34;color: #666666&#34;&gt;&amp;lt;&lt;/span&gt;String&lt;span style=&#34;color: #666666&#34;&gt;,&lt;/span&gt; String&lt;span style=&#34;color: #666666&#34;&gt;&amp;gt;&lt;/span&gt; records &lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt; consumer&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #7D9029&#34;&gt;poll&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;(100);&lt;/span&gt;

        &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;for&lt;/span&gt; &lt;span style=&#34;color: #666666&#34;&gt;(&lt;/span&gt;ConsumerRecord&lt;span style=&#34;color: #666666&#34;&gt;&amp;lt;&lt;/span&gt;String&lt;span style=&#34;color: #666666&#34;&gt;,&lt;/span&gt; String&lt;span style=&#34;color: #666666&#34;&gt;&amp;gt;&lt;/span&gt; record &lt;span style=&#34;color: #666666&#34;&gt;:&lt;/span&gt; records&lt;span style=&#34;color: #666666&#34;&gt;)&lt;/span&gt;
            System&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #7D9029&#34;&gt;out&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #7D9029&#34;&gt;printf&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;quot;offset = %d, key = %s, value = %s%n&amp;quot;&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;,&lt;/span&gt; record&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #7D9029&#34;&gt;offset&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;(),&lt;/span&gt; record&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #7D9029&#34;&gt;key&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;(),&lt;/span&gt; record&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #7D9029&#34;&gt;value&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;());&lt;/span&gt;
    &lt;span style=&#34;color: #666666&#34;&gt;}&lt;/span&gt;
&lt;span style=&#34;color: #666666&#34;&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Este consumidor buscará por records por &lt;code&gt;100ms&lt;/code&gt; y los imprimirá en la consola.&lt;/p&gt;

&lt;p&gt;Ahora veamos como regresar &lt;code&gt;offsets&lt;/code&gt; en distintos escenarios. &lt;code&gt;Consumer API&lt;/code&gt;
tiene operaciones &lt;code&gt;#seek&lt;/code&gt; que permiten estas funcionalidades. Mostraré una
forma sencilla de agregar estas operaciones utilizando &lt;code&gt;flags&lt;/code&gt;:&lt;/p&gt;

&lt;h3 id=&#34;regresar-al-offset-inicial&#34;&gt;Regresar al &lt;code&gt;offset&lt;/code&gt; inicial&lt;/h3&gt;

&lt;p&gt;La opción más común es regresar al inicio del &lt;code&gt;topic&lt;/code&gt;, que no siempre será
&lt;code&gt;offset=0&lt;/code&gt;. Esto dependerá de la política de &lt;code&gt;retention&lt;/code&gt; que removerá los
&lt;code&gt;records&lt;/code&gt; antiguos por tiempo o por tamaño del &lt;code&gt;topic&lt;/code&gt;; pero este tema
merece su propio post.&lt;/p&gt;

&lt;p&gt;Para ir al inicio de &lt;code&gt;topic&lt;/code&gt; usaremos la operación &lt;code&gt;#seekToBeginning(topicPartition)&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #f8f8f8&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span style=&#34;color: #B00040&#34;&gt;boolean&lt;/span&gt; flag &lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;true&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;;&lt;/span&gt;

&lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;while&lt;/span&gt; &lt;span style=&#34;color: #666666&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;true&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color: #666666&#34;&gt;{&lt;/span&gt;
    ConsumerRecords&lt;span style=&#34;color: #666666&#34;&gt;&amp;lt;&lt;/span&gt;String&lt;span style=&#34;color: #666666&#34;&gt;,&lt;/span&gt; String&lt;span style=&#34;color: #666666&#34;&gt;&amp;gt;&lt;/span&gt; records &lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt; consumer&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #7D9029&#34;&gt;poll&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;(100);&lt;/span&gt;

    &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;if&lt;/span&gt; &lt;span style=&#34;color: #666666&#34;&gt;(&lt;/span&gt;flag&lt;span style=&#34;color: #666666&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color: #666666&#34;&gt;{&lt;/span&gt;
        consumer&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #7D9029&#34;&gt;seekToBeginning&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;(&lt;/span&gt;
            Stream&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #7D9029&#34;&gt;of&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;new&lt;/span&gt; TopicPartition&lt;span style=&#34;color: #666666&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;quot;topic-1&amp;quot;&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #666666&#34;&gt;0)).&lt;/span&gt;&lt;span style=&#34;color: #7D9029&#34;&gt;collect&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;(&lt;/span&gt;toList&lt;span style=&#34;color: #666666&#34;&gt;()));&lt;/span&gt;
        flag &lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;false&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;;&lt;/span&gt;
    &lt;span style=&#34;color: #666666&#34;&gt;}&lt;/span&gt;

    &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;for&lt;/span&gt; &lt;span style=&#34;color: #666666&#34;&gt;(&lt;/span&gt;ConsumerRecord&lt;span style=&#34;color: #666666&#34;&gt;&amp;lt;&lt;/span&gt;String&lt;span style=&#34;color: #666666&#34;&gt;,&lt;/span&gt; String&lt;span style=&#34;color: #666666&#34;&gt;&amp;gt;&lt;/span&gt; record &lt;span style=&#34;color: #666666&#34;&gt;:&lt;/span&gt; records&lt;span style=&#34;color: #666666&#34;&gt;)&lt;/span&gt;
        &lt;span style=&#34;color: #408080; font-style: italic&#34;&gt;//Consume record&lt;/span&gt;
&lt;span style=&#34;color: #666666&#34;&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Una vez realizada la búsqueda del &lt;code&gt;offset&lt;/code&gt; inicial, para el &lt;code&gt;topic=topic-1&lt;/code&gt;
en la &lt;code&gt;partition=0&lt;/code&gt; se reprocesarán los &lt;code&gt;records&lt;/code&gt; nuevamente.&lt;/p&gt;

&lt;h3 id=&#34;regresar-a-un-offset-específico&#34;&gt;Regresar a un &lt;code&gt;offset&lt;/code&gt; específico&lt;/h3&gt;

&lt;p&gt;Si podemos reconocer los &lt;code&gt;records&lt;/code&gt; específicos (por &lt;code&gt;partition&lt;/code&gt;) a los que
necesitamos regresar para reprocesar el log, podemos utilizar
&lt;code&gt;#seek(topicPartition, offset)&lt;/code&gt; directamente.&lt;/p&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #f8f8f8&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span style=&#34;color: #B00040&#34;&gt;boolean&lt;/span&gt; flag &lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;true&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;;&lt;/span&gt;

&lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;while&lt;/span&gt; &lt;span style=&#34;color: #666666&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;true&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color: #666666&#34;&gt;{&lt;/span&gt;
    ConsumerRecords&lt;span style=&#34;color: #666666&#34;&gt;&amp;lt;&lt;/span&gt;String&lt;span style=&#34;color: #666666&#34;&gt;,&lt;/span&gt; String&lt;span style=&#34;color: #666666&#34;&gt;&amp;gt;&lt;/span&gt; records &lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt; consumer&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #7D9029&#34;&gt;poll&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;(100);&lt;/span&gt;

    &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;if&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;(&lt;/span&gt;flag&lt;span style=&#34;color: #666666&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color: #666666&#34;&gt;{&lt;/span&gt;
        consumer&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #7D9029&#34;&gt;seek&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;new&lt;/span&gt; TopicPartition&lt;span style=&#34;color: #666666&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;quot;topic-1&amp;quot;&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #666666&#34;&gt;0),&lt;/span&gt; &lt;span style=&#34;color: #666666&#34;&gt;90);&lt;/span&gt;
        flag &lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;false&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;;&lt;/span&gt;
    &lt;span style=&#34;color: #666666&#34;&gt;}&lt;/span&gt;

    &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;for&lt;/span&gt; &lt;span style=&#34;color: #666666&#34;&gt;(&lt;/span&gt;ConsumerRecord&lt;span style=&#34;color: #666666&#34;&gt;&amp;lt;&lt;/span&gt;String&lt;span style=&#34;color: #666666&#34;&gt;,&lt;/span&gt; String&lt;span style=&#34;color: #666666&#34;&gt;&amp;gt;&lt;/span&gt; record &lt;span style=&#34;color: #666666&#34;&gt;:&lt;/span&gt; records&lt;span style=&#34;color: #666666&#34;&gt;)&lt;/span&gt;
        System&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #7D9029&#34;&gt;out&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #7D9029&#34;&gt;printf&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;quot;offset = %d, key = %s, value = %s%n&amp;quot;&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;,&lt;/span&gt; record&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #7D9029&#34;&gt;offset&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;(),&lt;/span&gt; record&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #7D9029&#34;&gt;key&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;(),&lt;/span&gt; record&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #7D9029&#34;&gt;value&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;());&lt;/span&gt;
&lt;span style=&#34;color: #666666&#34;&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;En este casoo, retrocederemos en en &lt;code&gt;topic=topic-1&lt;/code&gt; &lt;code&gt;partition=0&lt;/code&gt;
hasta el &lt;code&gt;record&lt;/code&gt; con &lt;code&gt;offset=90&lt;/code&gt; y reprocesaremos los siguiente &lt;code&gt;records&lt;/code&gt;
del log.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;NOTA: Puede resultar engorroso mapear todos los offsets por partición cuando
tienes varias particiones. Por esto es que la adición de &lt;code&gt;timestamps&lt;/code&gt; ayuda
a resolver este tema.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;regrasar-a-un-offset-por-timestamp&#34;&gt;Regrasar a un &lt;code&gt;offset&lt;/code&gt; por &lt;code&gt;timestamp&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;Si no conoces exactamente el &lt;code&gt;offset id&lt;/code&gt; del &lt;code&gt;record&lt;/code&gt; desde donde necesitar
reprocesar el log, pero sabes si necesitas regresar 1 hora o 10 minutos atrás
el nuevo índice de &lt;code&gt;timestamp&lt;/code&gt; puede ser útil.&lt;/p&gt;

&lt;p&gt;Desde el release &lt;code&gt;0.10.1.0&lt;/code&gt;, hay un par de mejoras
&lt;a href=&#34;https://cwiki.apache.org/confluence/display/KAFKA/KIP-32+-+Add+timestamps+to+Kafka+message&#34;&gt;[2]&lt;/a&gt;
&lt;a href=&#34;https://cwiki.apache.org/confluence/display/KAFKA/KIP-33+-+Add+a+time+based+log+index&#34;&gt;[3]&lt;/a&gt;
que fueron implementadas, y una nueva operación fue agregada al
&lt;code&gt;Kafka Consumer API&lt;/code&gt;: &lt;code&gt;#offsetsForTimes&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #f8f8f8&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span style=&#34;color: #B00040&#34;&gt;boolean&lt;/span&gt; flag &lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;true&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;;&lt;/span&gt;

&lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;while&lt;/span&gt; &lt;span style=&#34;color: #666666&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;true&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color: #666666&#34;&gt;{&lt;/span&gt;
    ConsumerRecords&lt;span style=&#34;color: #666666&#34;&gt;&amp;lt;&lt;/span&gt;String&lt;span style=&#34;color: #666666&#34;&gt;,&lt;/span&gt; String&lt;span style=&#34;color: #666666&#34;&gt;&amp;gt;&lt;/span&gt; records &lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt; consumer&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #7D9029&#34;&gt;poll&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;(100);&lt;/span&gt;

    &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;if&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;(&lt;/span&gt;flag&lt;span style=&#34;color: #666666&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color: #666666&#34;&gt;{&lt;/span&gt;
        Map&lt;span style=&#34;color: #666666&#34;&gt;&amp;lt;&lt;/span&gt;TopicPartition&lt;span style=&#34;color: #666666&#34;&gt;,&lt;/span&gt; Long&lt;span style=&#34;color: #666666&#34;&gt;&amp;gt;&lt;/span&gt; query &lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;new&lt;/span&gt; HashMap&lt;span style=&#34;color: #666666&#34;&gt;&amp;lt;&amp;gt;();&lt;/span&gt;
        query&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #7D9029&#34;&gt;put&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;(&lt;/span&gt;
                &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;new&lt;/span&gt; TopicPartition&lt;span style=&#34;color: #666666&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;quot;simple-topic-1&amp;quot;&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #666666&#34;&gt;0),&lt;/span&gt;
                Instant&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #7D9029&#34;&gt;now&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;().&lt;/span&gt;&lt;span style=&#34;color: #7D9029&#34;&gt;minus&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;(10,&lt;/span&gt; MINUTES&lt;span style=&#34;color: #666666&#34;&gt;).&lt;/span&gt;&lt;span style=&#34;color: #7D9029&#34;&gt;toEpochMilli&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;());&lt;/span&gt;

        Map&lt;span style=&#34;color: #666666&#34;&gt;&amp;lt;&lt;/span&gt;TopicPartition&lt;span style=&#34;color: #666666&#34;&gt;,&lt;/span&gt; OffsetAndTimestamp&lt;span style=&#34;color: #666666&#34;&gt;&amp;gt;&lt;/span&gt; result &lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt; consumer&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #7D9029&#34;&gt;offsetsForTimes&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;(&lt;/span&gt;query&lt;span style=&#34;color: #666666&#34;&gt;);&lt;/span&gt;

        result&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #7D9029&#34;&gt;entrySet&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;()&lt;/span&gt;
                &lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #7D9029&#34;&gt;stream&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;()&lt;/span&gt;
                &lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #7D9029&#34;&gt;forEach&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;(&lt;/span&gt;entry &lt;span style=&#34;color: #666666&#34;&gt;-&amp;gt;&lt;/span&gt; consumer&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #7D9029&#34;&gt;seek&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;(&lt;/span&gt;entry&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #7D9029&#34;&gt;getKey&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;(),&lt;/span&gt; entry&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #7D9029&#34;&gt;getValue&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;().&lt;/span&gt;&lt;span style=&#34;color: #7D9029&#34;&gt;offset&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;()));&lt;/span&gt;

        flag &lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;false&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;;&lt;/span&gt;
    &lt;span style=&#34;color: #666666&#34;&gt;}&lt;/span&gt;

    &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;for&lt;/span&gt; &lt;span style=&#34;color: #666666&#34;&gt;(&lt;/span&gt;ConsumerRecord&lt;span style=&#34;color: #666666&#34;&gt;&amp;lt;&lt;/span&gt;String&lt;span style=&#34;color: #666666&#34;&gt;,&lt;/span&gt; String&lt;span style=&#34;color: #666666&#34;&gt;&amp;gt;&lt;/span&gt; record &lt;span style=&#34;color: #666666&#34;&gt;:&lt;/span&gt; records&lt;span style=&#34;color: #666666&#34;&gt;)&lt;/span&gt;
        System&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #7D9029&#34;&gt;out&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #7D9029&#34;&gt;printf&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;quot;offset = %d, key = %s, value = %s%n&amp;quot;&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;,&lt;/span&gt; record&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #7D9029&#34;&gt;offset&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;(),&lt;/span&gt; record&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #7D9029&#34;&gt;key&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;(),&lt;/span&gt; record&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #7D9029&#34;&gt;value&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;());&lt;/span&gt;
&lt;span style=&#34;color: #666666&#34;&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;En este caso primero estamos consultando cuál es el &lt;code&gt;offset&lt;/code&gt; al que tengo que
regresar si quiero reprocesar los &lt;code&gt;records&lt;/code&gt; de hacer 10 minutos,
y luego con el &lt;code&gt;offset&lt;/code&gt; adecuado, utilizamos la operación &lt;code&gt;#seek&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;En el código fuente se ha agregado los pasos para buscar las particiones por
&lt;code&gt;topic&lt;/code&gt;. Esto permitirá reproducir estos pasos en escenarios en los que tengamos
más de una partición por &lt;code&gt;topic&lt;/code&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Referencias&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.confluent.io/blog/data-reprocessing-with-kafka-streams-resetting-a-streams-application/&#34;&gt;https://www.confluent.io/blog/data-reprocessing-with-kafka-streams-resetting-a-streams-application/&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://cwiki.apache.org/confluence/display/KAFKA/KIP-32+-+Add+timestamps+to+Kafka+message&#34;&gt;https://cwiki.apache.org/confluence/display/KAFKA/KIP-32+-+Add+timestamps+to+Kafka+message&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://cwiki.apache.org/confluence/display/KAFKA/KIP-33+-+Add+a+time+based+log+index&#34;&gt;https://cwiki.apache.org/confluence/display/KAFKA/KIP-33+-+Add+a+time+based+log+index&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://cwiki.apache.org/confluence/display/KAFKA/FAQ#FAQ-HowcanIrewindtheoffsetintheconsumer&#34;&gt;https://cwiki.apache.org/confluence/display/KAFKA/FAQ#FAQ-HowcanIrewindtheoffsetintheconsumer&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;</description>
        </item>
        
        <item>
            <title>Escalando Kafka con Docker Containers</title>
            <link>https://jeqo.github.io/es/post/2017-01-15-scale-kafka-containers/</link>
            <pubDate>Sun, 15 Jan 2017 00:00:00 UTC</pubDate>
            <author>Jorge Quilcate Otoya</author>
            <guid>https://jeqo.github.io/es/post/2017-01-15-scale-kafka-containers/</guid>
            <description>&lt;p&gt;En este post mostraré como utilizar contenedores Docker para crear y escalar
un clúster de Kafka, y también como crear, escalar y mover &lt;code&gt;topics&lt;/code&gt; dentro del
clúster.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Repositorio: &lt;a href=&#34;https://github.com/jeqo/post-scale-kafka-containers&#34;&gt;https://github.com/jeqo/post-scale-kafka-containers&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;clúster-de-un-nodo&#34;&gt;Clúster de un nodo&lt;/h1&gt;

&lt;p&gt;Primero, comenzaremos con la forma más sencilla de utilizar Docker, que puede
ser útil y suficiente para algunos escenarios de desarrollo: un &lt;strong&gt;clúster con
un nodo&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;La arquitectura de &lt;em&gt;Apache Kafka&lt;/em&gt; esta basada en 2 components principales:
El propio &lt;em&gt;servidor de Apache Kakfa&lt;/em&gt;, y el &lt;em&gt;servidor de Apache Zookeeper&lt;/em&gt;,
utilizado por Kafka para su coordinación interna.&lt;/p&gt;

&lt;p&gt;Es por eso que un clúster de nodo simple require por lo menos de un par de
procesos.&lt;/p&gt;

&lt;p&gt;Si hablamos en terminos y prácticas de &lt;code&gt;contenedores&lt;/code&gt;, estos processos deberían
ejecutarse en dos contenedores diferentes.&lt;/p&gt;

&lt;p&gt;La forma más sencilla de definir estos procesos en Docker, es con
servicios de &lt;code&gt;Docker Compose&lt;/code&gt;, como están definidos en el archivo
&lt;code&gt;kafka-cluster/docker-compose.yml&lt;/code&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Usaré un par de imagenes. Son bastante simples, y el código fuente se encuentra
aquí:
&lt;a href=&#34;https://github.com/jeqo/docker-image-apache-kafka&#34;&gt;Apache Kafka&lt;/a&gt;,
&lt;a href=&#34;https://github.com/jeqo/docker-image-apache-zookeeper&#34;&gt;Apache Zookeeper&lt;/a&gt;, and
&lt;a href=&#34;https://github.com/jeqo/docker-image-confluent-platform&#34;&gt;Confluent Platform&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #f8f8f8&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;version: &lt;span style=&#34;color: #BA2121&#34;&gt;&amp;quot;2.1&amp;quot;&lt;/span&gt;
services:
  kafka:
    image: jeqo/apache-kafka:0.10.1.0-2.11
    links:
      - zookeeper
  zookeeper:
    image: jeqo/apache-zookeeper:3.4.8
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Esta configuración define 2 servicios: &lt;code&gt;kafka&lt;/code&gt; y &lt;code&gt;zookeeper&lt;/code&gt;. El &lt;code&gt;link&lt;/code&gt; del&lt;br /&gt;
servicio &lt;code&gt;kafka&lt;/code&gt; y su variable de entorno &lt;code&gt;ZOOKEEPER_CONNECT&lt;/code&gt;
configuran el acceso desde &lt;code&gt;kafka&lt;/code&gt; hacia el servicio &lt;code&gt;zookeeper&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Si probamos iniciar los servicios con el comando &lt;code&gt;docker-compose up -d&lt;/code&gt;,
Docker Compose creará una red donde estos servicios se podrán comunicar.&lt;/p&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #f8f8f8&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;jeqo@jeqo-Oryx-Pro:.../single-node-kafka-cluster$ docker-compose up -d
Creating network &lt;span style=&#34;color: #BA2121&#34;&gt;&amp;quot;kafkacluster_default&amp;quot;&lt;/span&gt; with the default driver
Creating kafkacluster_zookeeper_1
Creating kafkacluster_kafka_1
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Si queremos acceder a estos servicios desde nuestra aplicación (también
  definida en Docker Compose) lo podemos hacer de la siguiente manera:&lt;/p&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #f8f8f8&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;version: &lt;span style=&#34;color: #BA2121&#34;&gt;&amp;quot;2.1&amp;quot;&lt;/span&gt;
services:
  kafka:
    image: jeqo/apache-kafka-client:0.10.1.0-2.11
    command: sleep infinity
    networks:
      - default
      - kafkacluster_default &lt;span style=&#34;color: #408080; font-style: italic&#34;&gt;#(2)&lt;/span&gt;
networks: &lt;span style=&#34;color: #408080; font-style: italic&#34;&gt;#(1)&lt;/span&gt;
  kafkacluster_default:
    external: true
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Aquí definimos primero una red externa &lt;code&gt;external network&lt;/code&gt; llamada &lt;code&gt;singlenodekafkacluster_default&lt;/code&gt;
que nos permite acceder a la red del clúster de kafka.
Luego agregamos esta red a los servicios que requieren acceso, en este caso
el servicio &lt;code&gt;client&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Para probar el acceso desde el cliente, primero iniciemos el servicio con
&lt;code&gt;docker-compose up -d&lt;/code&gt; y luego nos conectamos al servicio:&lt;/p&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #f8f8f8&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;$ docker-compose &lt;span style=&#34;color: #008000&#34;&gt;exec&lt;/span&gt; kafka bash
&lt;span style=&#34;color: #408080; font-style: italic&#34;&gt;# bin/kafka-console-producer.sh --broker-list kafka:9092 --topic topic1&lt;/span&gt;
&lt;span style=&#34;color: #008000&#34;&gt;test&lt;/span&gt;
&lt;span style=&#34;color: #408080; font-style: italic&#34;&gt;# bin/kafka-topics.sh --zookeeper zookeeper:2181 --list      &lt;/span&gt;
topic1
&lt;/pre&gt;&lt;/div&gt;


&lt;h1 id=&#34;clúster-multi-nodo&#34;&gt;Clúster Multi-Nodo&lt;/h1&gt;

&lt;p&gt;Una vez creado nuestro clúster, escalar nuestro contenedor de ´kafka´
es tan sencillo como utilizar el comando &lt;code&gt;scale&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #f8f8f8&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;docker-compose scale &lt;span style=&#34;color: #19177C&#34;&gt;kafka&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;3
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Este comando creará dos contenedores adicionales:&lt;/p&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #f8f8f8&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;$ docker-compose scale &lt;span style=&#34;color: #19177C&#34;&gt;kafka&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;3
Creating and starting kafkacluster_kafka_2 ... &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;done&lt;/span&gt;
Creating and starting kafkacluster_kafka_3 ... &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;done&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Para nosotros, como desarrolladores(as) de aplicaciones, solo necesitamos
saber uno de los host o IPs de los &lt;code&gt;broker&lt;/code&gt; (nodo del clúster de Kafka),
para conectarnos al clúster. O también podemos usar el nombre del servicio.&lt;/p&gt;

&lt;p&gt;Como la documentación especifíca, el cliente (p.ejem: &lt;code&gt;productor&lt;/code&gt; o &lt;code&gt;consumidor&lt;/code&gt;)
solo utilizará este dato para iniciar la conexión y obtener la lista completa de
&lt;code&gt;brokers&lt;/code&gt; del clúster. Esto significa que la escalabilidad de Kafka es
transparente para nuestra aplicación.&lt;/p&gt;

&lt;p&gt;Para validar que todos los brokers son parte del clúster, usaremos el client
de Zookeeper.&lt;/p&gt;

&lt;p&gt;Desde el contenedor cliente:&lt;/p&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #f8f8f8&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;$ docker-compose &lt;span style=&#34;color: #008000&#34;&gt;exec&lt;/span&gt; kafka bash
&lt;span style=&#34;color: #408080; font-style: italic&#34;&gt;# bin/zookeeper-shell.sh zookeeper:2181&lt;/span&gt;
ls /brokers/ids
&lt;span style=&#34;color: #666666&#34;&gt;[&lt;/span&gt;1003, 1002, 1001&lt;span style=&#34;color: #666666&#34;&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h1 id=&#34;escalando-topics&#34;&gt;Escalando Topics&lt;/h1&gt;

&lt;p&gt;En Kafka, los &lt;code&gt;Topics&lt;/code&gt; son distribuidos en &lt;code&gt;Partitions&lt;/code&gt;. Las &lt;code&gt;Particiones&lt;/code&gt;
permiten la &lt;strong&gt;escalabilidad&lt;/strong&gt;, haciendo posible que los &lt;code&gt;Topics&lt;/code&gt; quepan en
varios nodos; y &lt;strong&gt;paralelismo&lt;/strong&gt;, dejando que distintas instancias de un mismo
&lt;strong&gt;Grupo de Consumidores&lt;/strong&gt; puedan consumir messages en paralelo.&lt;/p&gt;

&lt;p&gt;Aparte de este beneficio, Kafka tiene la habilidad de &lt;strong&gt;replicar&lt;/strong&gt; estas
&lt;code&gt;Particiones&lt;/code&gt;, logrando alta disponibilidad. En este case, si tienes varias &lt;code&gt;replicas&lt;/code&gt;
de una &lt;code&gt;partición&lt;/code&gt;, una será la partición &lt;code&gt;líder&lt;/code&gt; y las demás replicas serán
&lt;code&gt;seguidoras&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&#34;agregando-nuevos-topics-al-clúster&#34;&gt;Agregando nuevos &lt;code&gt;Topics&lt;/code&gt; al clúster&lt;/h2&gt;

&lt;p&gt;Una vez que el clúster tiene mayor número de nodos, Kafka no utilizará estos
nuevos nodos hasta que nuevos tópicos sean creados.&lt;/p&gt;

&lt;p&gt;Veamos como probamos esto:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Iniciemos un clúster simple, con un solo nodo&lt;/li&gt;
&lt;/ol&gt;

&lt;script type=&#34;text/javascript&#34; src=&#34;https://asciinema.org/a/9xzqgicktaqhzp1fofjk9ejgm.js&#34; id=&#34;asciicast-9xzqgicktaqhzp1fofjk9ejgm&#34; async&gt;&lt;/script&gt;

&lt;ol&gt;
&lt;li&gt;Luego iniciemos un cliente, y creemos un topic &lt;code&gt;topic1&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;script type=&#34;text/javascript&#34; src=&#34;https://asciinema.org/a/2schnuetb24mjx6txopew51hc.js&#34; id=&#34;asciicast-2schnuetb24mjx6txopew51hc&#34; async&gt;&lt;/script&gt;

&lt;ol&gt;
&lt;li&gt;Escalemos el clúster a 3 nodos&lt;/li&gt;
&lt;/ol&gt;

&lt;script type=&#34;text/javascript&#34; src=&#34;https://asciinema.org/a/ahibdzz7xt67q53sc5ert6qdp.js&#34; id=&#34;asciicast-ahibdzz7xt67q53sc5ert6qdp&#34; async&gt;&lt;/script&gt;

&lt;ol&gt;
&lt;li&gt;Agregemos topics para ocupar los demás brokers&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Usando múltiples particiones:&lt;/p&gt;

&lt;script type=&#34;text/javascript&#34; src=&#34;https://asciinema.org/a/enq2czkpgdf0tbf3u6fwir3ml.js&#34; id=&#34;asciicast-enq2czkpgdf0tbf3u6fwir3ml&#34; async&gt;&lt;/script&gt;

&lt;p&gt;O usando varias réplicas:&lt;/p&gt;

&lt;script type=&#34;text/javascript&#34; src=&#34;https://asciinema.org/a/f0u67h5ufiz4zkup84a1t8t5g.js&#34; id=&#34;asciicast-f0u67h5ufiz4zkup84a1t8t5g&#34; async&gt;&lt;/script&gt;

&lt;p&gt;Para decidir que &lt;code&gt;factor de replicación&lt;/code&gt; utilizar o cuantas  &lt;code&gt;particiones&lt;/code&gt;,
depende de cada caso de uso. Estos temas merecen su propio post.&lt;/p&gt;

&lt;h2 id=&#34;expandiendo-topics-en-el-clúster&#34;&gt;Expandiendo &lt;code&gt;Topics&lt;/code&gt; en el clúster&lt;/h2&gt;

&lt;p&gt;Expandir topics en el clúster significa mover &lt;code&gt;topics&lt;/code&gt; y &lt;code&gt;particiones&lt;/code&gt;
una vez que se tengan más &lt;code&gt;brokers&lt;/code&gt; en el &lt;code&gt;clúster&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Esto se puede realizar en 3 pasos:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Identificar que &lt;code&gt;topics&lt;/code&gt; se quieren mover a un nuevo &lt;code&gt;broker&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Generar el plan de reasignación. Esto se puede realizar de forma automática
o manual, si se sabe cómo redistribuir los topics.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Ejecutar el plan de reasignación.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Estos pasos se encuentran documentados aquí: &lt;a href=&#34;http://kafka.apache.org/documentation/#basic_ops_cluster_expansion&#34;&gt;http://kafka.apache.org/documentation/#basic_ops_cluster_expansion&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;He automatizado un poco los pasos con unos script en Ansible:&lt;/p&gt;

&lt;p&gt;Dentro del archivo &lt;code&gt;playbooks/prepare-reassignment.yml&lt;/code&gt; hay dos variables a definir:&lt;/p&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #f8f8f8&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;vars:
  topics:
    - topic1
  broker_list: 1003
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Estas prepararán un plan para mover el topic &lt;code&gt;topic1&lt;/code&gt; al &lt;code&gt;broker&lt;/code&gt; con id &lt;code&gt;1003&lt;/code&gt;.&lt;/p&gt;

&lt;script type=&#34;text/javascript&#34; src=&#34;https://asciinema.org/a/c6332x8t7yumpj65ie4qudgem.js&#34; id=&#34;asciicast-c6332x8t7yumpj65ie4qudgem&#34; async&gt;&lt;/script&gt;

&lt;p&gt;Puedes copiar ese JSON generado en &lt;code&gt;playbooks/reassign-topic-plan.json&lt;/code&gt;&lt;/p&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #f8f8f8&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;{
  &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;&amp;quot;version&amp;quot;&lt;/span&gt;:&lt;span style=&#34;color: #666666&#34;&gt;1&lt;/span&gt;,
  &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;&amp;quot;partitions&amp;quot;&lt;/span&gt;:[{&lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;&amp;quot;topic&amp;quot;&lt;/span&gt;:&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;quot;topic1&amp;quot;&lt;/span&gt;,&lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;&amp;quot;partition&amp;quot;&lt;/span&gt;:&lt;span style=&#34;color: #666666&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;&amp;quot;replicas&amp;quot;&lt;/span&gt;:[&lt;span style=&#34;color: #666666&#34;&gt;1003&lt;/span&gt;]}]
}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Y ejecutar el otro playbook: &lt;code&gt;playbooks/execute-reassignment.yml&lt;/code&gt;&lt;/p&gt;

&lt;script type=&#34;text/javascript&#34; src=&#34;https://asciinema.org/a/99308.js&#34; id=&#34;asciicast-99308&#34; async&gt;&lt;/script&gt;

&lt;h1 id=&#34;confluent-platform-images&#34;&gt;Confluent Platform images&lt;/h1&gt;

&lt;p&gt;Todos estos pasos se pueden ejecutar igualmente con
&lt;a href=&#34;https://www.confluent.io/&#34;&gt;Confluent Platform&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Para ello, agregué los directorios &lt;code&gt;confluent-cluster&lt;/code&gt; y &lt;code&gt;confluent-client&lt;/code&gt; para
poder probarlo:&lt;/p&gt;

&lt;script type=&#34;text/javascript&#34; src=&#34;https://asciinema.org/a/a446bixdfn3l8xqoiolmsmlqg.js&#34; id=&#34;asciicast-a446bixdfn3l8xqoiolmsmlqg&#34; async&gt;&lt;/script&gt;

&lt;p&gt;Espero que este post los ayude a entender un poco más sobre los &lt;code&gt;topics&lt;/code&gt; en
Kafka y como los &lt;code&gt;contenedores&lt;/code&gt; nos pueden ayudar a crear clústers en segundos :)&lt;/p&gt;

&lt;p&gt;Y, ya saben, ejecuten &amp;hellip;&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-lang=&#34;es&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;.&lt;a href=&#34;https://twitter.com/apachekafka&#34;&gt;@apachekafka&lt;/a&gt; everywhere :) &lt;a href=&#34;https://t.co/AcEmkRBCpv&#34;&gt;pic.twitter.com/AcEmkRBCpv&lt;/a&gt;&lt;/p&gt;&amp;mdash; Gwen (Chen) Shapira (@gwenshap) &lt;a href=&#34;https://twitter.com/gwenshap/status/777660752626851840&#34;&gt;19 de septiembre de 2016&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;//platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;</description>
        </item>
        
        <item>
            <title>Integrar Java EE 7 y Kafka usando Avro y RxJava</title>
            <link>https://jeqo.github.io/es/post/2015-07-31-java-ee-rxjava-kafka-avro/</link>
            <pubDate>Fri, 31 Jul 2015 00:00:00 UTC</pubDate>
            <author>Jorge Quilcate Otoya</author>
            <guid>https://jeqo.github.io/es/post/2015-07-31-java-ee-rxjava-kafka-avro/</guid>
            <description>

&lt;p&gt;Hace poco decidi probar una rápida implementación entre aplicaciones
Java EE y RxJava/Kafka/Avro, para publicar/subscribirse a &amp;ldquo;topic messages&amp;rdquo;.&lt;/p&gt;

&lt;p&gt;Puedes ir directamente al &lt;a href=&#34;https://github.com/jeqo/java-ee-rxjava-kafka-avro&#34;&gt;código&lt;/a&gt;,
o revisar el enfoque que apliqué:&lt;/p&gt;

&lt;h2 id=&#34;tl-dr&#34;&gt;TL;DR&lt;/h2&gt;

&lt;p&gt;He estado realizando alguna pruebas de concepto con &lt;a href=&#34;http://kafka.apache.org/&#34;&gt;Kafka&lt;/a&gt;
seducido por los beneficios que propone (rapidez, escalabilidad, y funcionar como
una fuente de eventos durable) para implementar una propagación de eventos
usando el patrón &amp;ldquo;Publish/Subscribe&amp;rdquo;.&lt;/p&gt;

&lt;p&gt;En estos momentos que estoy escribiendo esta entrada del blog, me he dado cuenta
que las APIs para acceder a Kafka están en constante evolución y volviéndose
más simples de utilizar, y no ha sido fácil encontrar un ejemplo con la versión
actual. Estoy utilizando el &lt;strong&gt;release 0.8.2.1&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Logré encontrar este tutorial sobre como utilizar las APIs para &lt;em&gt;publicar&lt;/em&gt;
y &lt;em&gt;suscribirse&lt;/em&gt; a mensajes: &lt;a href=&#34;https://github.com/mdkhanga/my-blog-code&#34;&gt;https://github.com/mdkhanga/my-blog-code&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Kafka soporta 2 tipos de mensajes : &lt;em&gt;Strings&lt;/em&gt; and &lt;em&gt;byte[]&lt;/em&gt;. Luego de hacer
algunas pruebas con String, requería enviar POJOs como mensajes. Y encontré
otro proyecto de Apache: &lt;a href=&#34;https://avro.apache.org&#34;&gt;Avro&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Utilizando los tutoriales de Avro (&lt;a href=&#34;https://avro.apache.org/docs/current/gettingstartedjava.html&#34;&gt;https://avro.apache.org/docs/current/gettingstartedjava.html&lt;/a&gt;)
y otras fuentes: (&lt;a href=&#34;https://github.com/wpm/AvroExample&#34;&gt;https://github.com/wpm/AvroExample&lt;/a&gt;)
Encontre como Serializar/Deserializar POJO de una forma eficiente, sin necesidad
de persistir archivos en disco, solo manteniendolos como ByteStreams.&lt;/p&gt;

&lt;p&gt;En este punto tengo Eventos, definidos por &lt;a href=&#34;https://avro.apache.org/docs/current/spec.html#schema_record&#34;&gt;esquemas de Avro&lt;/a&gt;,
y APIs de Kafka listo para publicar y suscribirse a &amp;ldquo;topics&amp;rdquo;.&lt;/p&gt;

&lt;p&gt;Finalmente, quiero agregar esta características a mi aplicación Java EE 7.&lt;/p&gt;

&lt;p&gt;Primero, usando CDI, fue sencillo inyectar un &amp;ldquo;Producer&amp;rdquo; y publicar mensajes,
pero cuando se necesita consumir mensajes, el enfoque cambia. Ya no se trata
de enviar mensajes, pero consumir un &amp;ldquo;stream&amp;rdquo; de eventos. Así llegue a encontrarme
con &lt;a href=&#34;https://github.com/ReactiveX/RxJava&#34;&gt;RxJava&lt;/a&gt; que aplica conceptos como
&lt;a href=&#34;http://reactivex.io/documentation/observable.html&#34;&gt;&lt;strong&gt;Observables&lt;/strong&gt;&lt;/a&gt; y &lt;strong&gt;Subscribers&lt;/strong&gt;
que cubre mis requerimientos: cada Kafka topic será un stream &amp;ldquo;observable&amp;rdquo; y
cada Consumer se suscribirá a este &amp;ldquo;observable&amp;rdquo;. Revisemos el código:&lt;/p&gt;

&lt;h2 id=&#34;sample-java-ee-app&#34;&gt;Sample Java EE App&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/jeqo/java-ee-rxjava-kafka-avro/releases/tag/v0.0.1&#34;&gt;Tag: v0.0.1&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;El primer paso fue tener un par de operaciones REST, implementados con JAX-RS:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Clients Resource: List (GET) and Add (POST) Clients&lt;/li&gt;
&lt;li&gt;Events Resource: List (GET) Client Added Events&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@Path(&amp;quot;clients&amp;quot;)
public class ClientsResource {

    static List&amp;lt;String&amp;gt; clients = new ArrayList&amp;lt;&amp;gt;();

    @GET
    @Produces(MediaType.APPLICATION_JSON)
    public List&amp;lt;String&amp;gt; getClients() {
        return clients;
    }

    @POST
    public void addClient(String client) {
        clients.add(client);
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Luego de tener mi recurso &amp;ldquo;Clients&amp;rdquo; implementado, mi requerimiento es
propagar el evento &amp;ldquo;ClientAddedEvent&amp;rdquo; y listarlo en el recurso Events.&lt;/p&gt;

&lt;h2 id=&#34;serialización-y-deserialización-de-eventos&#34;&gt;Serialización y Deserialización de Eventos&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/jeqo/java-ee-rxjava-kafka-avro/releases/tag/v0.0.2&#34;&gt;Tag: v0.0.2&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public void test() {
    ClientAddedEvent event = ClientAddedEvent.newBuilder()
            .setName(&amp;quot;jeqo&amp;quot;)
            .setCreated(new Date().getTime())
            .build();
    byte[] eventSerialized = serializer.serialize(event);
    ClientAddedEvent eventDeserialized = deserializer.deserialize(eventSerialized);
    assertEquals(event, eventDeserialized);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;El event ClientAddedEvent es definido usando el formato Avro JSON:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
    &amp;quot;namespace&amp;quot;: &amp;quot;com.jeqo.samples.eventsource.event&amp;quot;,
    &amp;quot;type&amp;quot;: &amp;quot;record&amp;quot;,
    &amp;quot;name&amp;quot;: &amp;quot;ClientAddedEvent&amp;quot;,
    &amp;quot;fields&amp;quot;: [
        {&amp;quot;name&amp;quot;: &amp;quot;name&amp;quot;, &amp;quot;type&amp;quot;: &amp;quot;string&amp;quot;},
        {&amp;quot;name&amp;quot;: &amp;quot;created&amp;quot;, &amp;quot;type&amp;quot;: &amp;quot;long&amp;quot;}
    ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Agregando el siguiente plugin de Maven, la clase  &lt;em&gt;ClientAddedEvent&lt;/em&gt; se
creará cada vez que el proyecto sea construido:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;build&amp;gt;
    &amp;lt;plugins&amp;gt;
        &amp;lt;plugin&amp;gt;
            &amp;lt;groupId&amp;gt;org.apache.avro&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;avro-maven-plugin&amp;lt;/artifactId&amp;gt;
            &amp;lt;version&amp;gt;1.7.7&amp;lt;/version&amp;gt;
            &amp;lt;executions&amp;gt;
                &amp;lt;execution&amp;gt;
                    &amp;lt;phase&amp;gt;generate-sources&amp;lt;/phase&amp;gt;
                    &amp;lt;goals&amp;gt;
                        &amp;lt;goal&amp;gt;schema&amp;lt;/goal&amp;gt;
                    &amp;lt;/goals&amp;gt;
                    &amp;lt;configuration&amp;gt;
                        &amp;lt;sourceDirectory&amp;gt;${project.basedir}/src/main/avro/&amp;lt;/sourceDirectory&amp;gt;
                        &amp;lt;outputDirectory&amp;gt;${project.basedir}/src/main/java/&amp;lt;/outputDirectory&amp;gt;
                    &amp;lt;/configuration&amp;gt;
                &amp;lt;/execution&amp;gt;
            &amp;lt;/executions&amp;gt;
        &amp;lt;/plugin&amp;gt;
    &amp;lt;/plugins&amp;gt;
&amp;lt;/build&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Para serializar Avro records, de POJO a Byte Array:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class EventSerializer&amp;lt;T extends SpecificRecordBase&amp;gt; {

    public byte[] serialize(T record) {
        try (ByteArrayOutputStream out = new ByteArrayOutputStream()) {
            Encoder encoder = EncoderFactory.get().binaryEncoder(out, null);
            new SpecificDatumWriter&amp;lt;&amp;gt;(record.getSchema()).write(record, encoder);
            encoder.flush();
            return out.toByteArray();
        } catch (IOException ex) {
            throw new RuntimeException(&amp;quot;Error serializing event&amp;quot;, ex);
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;y viceversa:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class EventDeserializer&amp;lt;T extends SpecificRecordBase&amp;gt; {

    private final Class&amp;lt;T&amp;gt; type;

    public EventDeserializer(Class&amp;lt;T&amp;gt; type) {
        this.type = type;
    }

    public T deserialize(byte[] recordSerialized) {
        try {
            return new SpecificDatumReader&amp;lt;&amp;gt;(type).read(
                    null,
                    DecoderFactory.get()
                    .binaryDecoder(recordSerialized, null)
            );
        } catch (IOException ex) {
            throw new RuntimeException(&amp;quot;Error deserializing event&amp;quot;, ex);
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;publicando-y-consumiendo-eventos-desde-kafka-rxjava&#34;&gt;Publicando y consumiendo eventos desde Kafka/RxJava&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/jeqo/java-ee-rxjava-kafka-avro/releases/tag/v0.0.3&#34;&gt;Tag: v0.0.3&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Primero, definamos un par de interfaces, EventServer:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public interface EventServer&amp;lt;T&amp;gt; {

    public Observable&amp;lt;T&amp;gt; consume();
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;y EventProducer:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public interface EventProducer&amp;lt;T&amp;gt; {

    public void publish(T message);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Luego, implementemos estas interfaces con Kafka APIs.&lt;/p&gt;

&lt;p&gt;Para publicar mensajes:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@Override
public void publish(T message) {
    // Produce a new Kafka record
    ProducerRecord&amp;lt;String, byte[]&amp;gt; data = new ProducerRecord&amp;lt;&amp;gt;(
            message.getClass().getSimpleName(),
            serializer.serialize(message)
    );

    // Publish this new record, waiting for acknowledge from Kafka
    Future&amp;lt;RecordMetadata&amp;gt; rs = producerProvider.producer()
            .send(data, (RecordMetadata recordMetadata, Exception e) -&amp;gt; {
                LOGGER.log(Level.INFO, &amp;quot;Received ack for partition={0} offset = {1}&amp;quot;, new Object[]{recordMetadata.partition(), recordMetadata.offset()});
            });

    try {
        RecordMetadata rm = rs.get();

        LOGGER.log(Level.INFO, &amp;quot;Kafka Record Metadata: partition = {0} offset ={1}&amp;quot;, new Object[]{rm.partition(), rm.offset()});

    } catch (InterruptedException | ExecutionException e) {
        System.out.println(e);
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;y en KafkaEventServer, para instanciar un RxJava observable:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@Override
public Observable&amp;lt;T&amp;gt; consume() {
    return Observable.create(subscriber -&amp;gt; {
        try {
            LOGGER.log(Level.INFO, &amp;quot;Preparing Server for Event {0}&amp;quot;, type.getName());
            // It will observe one Topic
            Map&amp;lt;String, Integer&amp;gt; topicCountMap = new HashMap&amp;lt;&amp;gt;();
            topicCountMap.put(type.getSimpleName(), 1);

            // consumerProvider will instantiate a consumer that will create a KafkaStream
            Map&amp;lt;String, List&amp;lt;KafkaStream&amp;lt;byte[], byte[]&amp;gt;&amp;gt;&amp;gt; consumerMap
                    = consumerProvider.consumer()
                    .createMessageStreams(topicCountMap);

            // then I will ask for the Stream from my topic, defined by Avro Record Class name
            List&amp;lt;KafkaStream&amp;lt;byte[], byte[]&amp;gt;&amp;gt; streams = consumerMap
                    .get(type.getSimpleName());

            KafkaStream&amp;lt;byte[], byte[]&amp;gt; stream = streams.get(0);

            ConsumerIterator&amp;lt;byte[], byte[]&amp;gt; it = stream.iterator();

            // on each message published on topic, I will let the subscriber receive the new message
            while (it.hasNext()) {
                subscriber.onNext(
                        deserializer.deserialize(it.next().message())
                );
            }
        } catch (Exception ex) {
            subscriber.onError(ex);
        }
    });
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Se puede validar la clase *Provider para observar como se genera la conexión
con Kafka, tanto para el Publisher como para el Subscriber.&lt;/p&gt;

&lt;p&gt;En el tag v0.0.3 se puede ejecutar cada clase (KafkaEventServer and KafkaEventProducer)
para validar que el servidor Kafka esta trabajando correctamente.&lt;/p&gt;

&lt;h2 id=&#34;uniendo-todo&#34;&gt;Uniendo todo&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/jeqo/java-ee-rxjava-kafka-avro/releases/tag/v0.1.0&#34;&gt;Tag: v0.1.0&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Finalmente, vamos a integrar la aplicación Java EE interacción con la nuestra
fuente de eventos (Kafka):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@ApplicationScoped
public class ClientAddedEventProducer extends KafkaEventProducer&amp;lt;ClientAddedEvent&amp;gt; {

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;La anotación @ApplicationScoped de CDI indica que esta clase se instanciará como
&lt;em&gt;&amp;ldquo;singleton&amp;rdquo;&lt;/em&gt; y podrá ser inyectada:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class ClientsResource {

    @Inject
    ClientAddedEventProducer eventProducer;

    //code

    @POST
    public void addClient(String client) {
        clients.add(client);
        //Publishing events
        eventProducer.publish(
                ClientAddedEvent.newBuilder()
                .setName(client)
                .setCreated(new Date().getTime())
                .build()
        );
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Luego para instanciar el &lt;em&gt;Subscriber&lt;/em&gt; (Creo que es la parte más importante:
como &lt;strong&gt;reaccionar&lt;/strong&gt; a eventos? ):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;// Extending Subscriber RxJava class to listen Observables
@ApplicationScoped
public class ClientAddedEventSubscriber extends Subscriber&amp;lt;ClientAddedEvent&amp;gt; {

    static final Logger LOGGER = Logger.getLogger(ClientAddedEventSubscriber.class.getName());

    // This will add a new thread to our pool, to subscribe to our Observable
    @Resource(name = &amp;quot;DefaultManagedExecutorService&amp;quot;)
    private ManagedExecutorService executor;

    @Inject
    private KafkaConsumerProvider consumerProvider;

    private Subscription subscription;

    // Run this on server startup, using CDI annotations
    public void init(@Observes @Initialized(ApplicationScoped.class) Object init) {
        LOGGER.log(Level.INFO, &amp;quot;Starting subscription&amp;quot;);
        subscription = new KafkaEventServer&amp;lt;&amp;gt;(
                ClientAddedEvent.class,
                consumerProvider,
                executor
        ).consume().subscribe(this);
    }

    public void destroy(@Observes @Destroyed(ApplicationScoped.class) Object init) {
        subscription.unsubscribe();
    }

    @Override
    public void onCompleted() {
        throw new UnsupportedOperationException(&amp;quot;Not supported yet.&amp;quot;);
    }

    @Override
    public void onError(Throwable e) {
        throw new UnsupportedOperationException(&amp;quot;Not supported yet.&amp;quot;);
    }

    @Override
    public void onNext(ClientAddedEvent t) {
        LOGGER.log(Level.INFO, &amp;quot;Event received {0}&amp;quot;, t);
        // How we will react to events:
        EventsResource.events.add(
                &amp;quot;Client Added: &amp;quot; + t.getName() + &amp;quot; at &amp;quot; + new Date(t.getCreated())
        );
    }

}
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
        
    </channel>
</rss>
