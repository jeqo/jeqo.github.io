<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>@jeqo</title>
    <link>https://jeqo.github.io/</link>
    <description>Recent content on @jeqo</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; Copyright @jeqo</copyright>
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
    <lastBuildDate>Sat, 24 Sep 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://jeqo.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Ingesting log files to sqlite</title>
      <link>https://jeqo.github.io/notes/2022-09-24-ingest-logs-sqlite/</link>
      <pubDate>Sat, 24 Sep 2022 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/notes/2022-09-24-ingest-logs-sqlite/</guid>
      <description>I recently was looking into how to analyze multiple related log files (e.g. application log from multiple instances), and found that sqlite may be enough :)
The first step is ingesting content from log files into sqlite tables. sqlite-utils to the rescue! I was initially happy with having each line as a row and adding full-text support to the log column to query events. However, a Java log may span across multiple lines and the outputs may not be ideal — timestamps could be in 1 line, and the stack trace root cause in another one.</description>
=======
=======
>>>>>>> f2734dc (rebuilding site)
    <lastBuildDate>Sat, 05 Nov 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://jeqo.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>On Anarchism book</title>
      <link>https://jeqo.github.io/notes/on-anarchism-book/</link>
      <pubDate>Sat, 05 Nov 2022 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/notes/on-anarchism-book/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://www.goodreads.com/book/show/22558046-on-anarchism&#34;&gt;On Anarchism&lt;/a&gt; by Noam Chomsky&lt;/p&gt;</description>
<<<<<<< HEAD
>>>>>>> e4753a1 (rebuilding site)
    </item>
    
=======
    <lastBuildDate>Wed, 24 Aug 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://jeqo.github.io/index.xml" rel="self" type="application/rss+xml" />
>>>>>>> 17fe1b7 (Revert "rebuilding site")
=======
    </item>
    
    <item>
      <title>Ingesting log files to sqlite</title>
      <link>https://jeqo.github.io/notes/2022-09-24-ingest-logs-sqlite/</link>
      <pubDate>Sat, 24 Sep 2022 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/notes/2022-09-24-ingest-logs-sqlite/</guid>
      <description>I recently was looking into how to analyze multiple related log files (e.g. application log from multiple instances), and found that sqlite may be enough :)
The first step is ingesting content from log files into sqlite tables. sqlite-utils to the rescue! I was initially happy with having each line as a row and adding full-text support to the log column to query events. However, a Java log may span across multiple lines and the outputs may not be ideal — timestamps could be in 1 line, and the stack trace root cause in another one.</description>
    </item>
    
>>>>>>> f2734dc (rebuilding site)
    <item>
      <title>Kafka Emulator CLI: Record and Reply Records considering time-distance</title>
      <link>https://jeqo.github.io/posts/2022-08-24-kafka-cli-emulator/</link>
      <pubDate>Wed, 24 Aug 2022 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/posts/2022-08-24-kafka-cli-emulator/</guid>
      <description>Looking for alternative ways to reproduce time-based conditions in Kafka Streams applications —e.g. if you&amp;rsquo;re doing some sort of join or windowing based on time— I ended up creating a CLI tool to support a couple of features:
Record events from topics, including their timestamps and gap Replay events, including waiting periods between them SQLite is used a storage for recorded events, so events can be generated, updated, tweaked using SQL.</description>
    </item>
    
    <item>
      <title>Piggyback on Kafka Connect Schemas to process Kafka records in a generic way</title>
      <link>https://jeqo.github.io/notes/2022-08-24-kafka-connect-schema-serde/</link>
      <pubDate>Wed, 24 Aug 2022 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/notes/2022-08-24-kafka-connect-schema-serde/</guid>
      <description>When reading from/writing to Kafka topics, a serializer/deserializer (a.k.a SerDes) is needed to process record key and value bytes. Specific SerDes that turn bytes into specific objects (e.g. POJO) are used, unless a generic JSON object or Avro structure is used.
Kafka Connect has to deal with generic structures to apply message transformations and convert messages from external sources into Kafka records and vice-versa. It has a SchemaAndValue composed type that includes a Connect Schema type derived from Schema Registry or JSON Schema included in the payload, and a value object.</description>
    </item>
    
    <item>
      <title>Kafka Streams: Tick stream-time with control messages</title>
      <link>https://jeqo.github.io/posts/2022-06-17-kafka-streams-tick-event-time-with-control-messages/</link>
      <pubDate>Fri, 17 Jun 2022 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/posts/2022-06-17-kafka-streams-tick-event-time-with-control-messages/</guid>
      <description>&lt;p&gt;Kafka Streams is in many ways governed by the concept of time.
For instance, as soon as stateful operations are used, the event-time drives how events are grouped, joined, and emitted.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://developer.confluent.io/learn-kafka/kafka-streams/time-concepts/#stream-time&#34;&gt;Stream-time&lt;/a&gt;
is the concept within Kafka Streams representing the largest timestamp seen by the the stream application (per-partition).
In comparison with wall-clock time (i.e. system time) — at the execution of an application — stream-time is driven by the data seen by the application.
This ensures that the results produced by a Kafka Streams application are reproducible.&lt;/p&gt;
&lt;p&gt;One nuance of stream-time is that it &lt;em&gt;needs&lt;/em&gt; incoming events to &amp;ldquo;tick&amp;rdquo;.
This could represent an issue for events that are sparse in time, and we expect results to be produced more often (e.g. windows to be closed and emit, punctiation to be calculated).&lt;/p&gt;
&lt;p&gt;This is a known issue, and there are some proposals to overcome it in certain parts of the framework,
e.g. &lt;a href=&#34;https://cwiki.apache.org/confluence/display/KAFKA/KIP-424%3A+Allow+suppression+of+intermediate+events+based+on+wall+clock+time&#34;&gt;KIP-424&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This post covers a proof-of-concept instrumenting producers to emit contol messages to advance stream time.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Getting started with Kafka quotas</title>
      <link>https://jeqo.github.io/posts/2022-05-11-kafka-quotas/</link>
      <pubDate>Wed, 11 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/posts/2022-05-11-kafka-quotas/</guid>
      <description>&lt;p&gt;Kafka quotas have been around for a while since initial versions of the project — though not necessarily being enabled in most deployments that I have seen.&lt;/p&gt;
&lt;p&gt;This post shares some thoughts on how to start adopting quotas and gives some practical advice, and a bit of the history of quotas in the Kafka project.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>sqlite can be used document and graph database</title>
      <link>https://jeqo.github.io/notes/2022-05-09-sqlite-as-document-and-graph-db/</link>
      <pubDate>Mon, 09 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/notes/2022-05-09-sqlite-as-document-and-graph-db/</guid>
      <description>I found that the use-cases for sqlite keep increasing now the JSON is supported.
This week I found the following presentation: https://www.hytradboi.com/2022/simple-graph-sqlite-as-probably-the-only-graph-database-youll-ever-need Which makes the case for a simple graph schema, and using SQL out-of-the-box functionality to store graphs and execute traversal queries.
This repository is actually based on this one focused on JSON support and document databases: https://dgl.cx/2020/06/sqlite-json-support</description>
    </item>
    
    <item>
      <title>Kafka client applications with GraalVM</title>
      <link>https://jeqo.github.io/posts/2022-03-18-kafka-clients-graalvm/</link>
      <pubDate>Fri, 18 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/posts/2022-03-18-kafka-clients-graalvm/</guid>
      <description>&lt;p&gt;Shipping CLI binaries with Java hasn&amp;rsquo;t been the most user-friendly experience.
Java is required to be installed on the client-side, starting Java applications (e.g. executable JAR) tend to be slower than to binary applications.&lt;/p&gt;
&lt;p&gt;GraalVM, and specifically &lt;a href=&#34;https://www.graalvm.org/22.0/reference-manual/native-image/&#34;&gt;native-image&lt;/a&gt; tooling, is aimed to tackle most of these issues with Java by enable building native binaries from Java applications.&lt;/p&gt;
&lt;p&gt;Even though this has been supported for a while now, reflection and other practices require additional configurations that make this process either unsupported or very cumbersome to implement.&lt;/p&gt;
&lt;p&gt;With the arrival of new frameworks that target the benefits of GraalVM, like &lt;a href=&#34;https://micronaut.io/&#34;&gt;Micronaut&lt;/a&gt; and &lt;a href=&#34;https://quarkus.io/&#34;&gt;Quarkus&lt;/a&gt;, it started to be possible and simpler to implement applications that included Kafka clients, and package them as native binaries.&lt;/p&gt;
&lt;p&gt;This post is going to explore the steps to package &lt;em&gt;vanilla&lt;/em&gt; Kafka client applications —i.e. no framework— as native binaries.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Explore Kafka data with kcat, sqlite, and Datasette</title>
      <link>https://jeqo.github.io/notes/2022-03-10-kcat-end-offset-and-datasette/</link>
      <pubDate>Thu, 10 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/notes/2022-03-10-kcat-end-offset-and-datasette/</guid>
      <description>&lt;p&gt;I have been playing with Datasette and sqlite for a bit, trying to collect and expose data efficiently for others to analyze.
Recently started finding use-cases to get data from Apache Kafka, and expose it quickly to analyze it.
Why not using Datasette?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Releasing OS-specific GraalVM native image binaries easier with JReleaser</title>
      <link>https://jeqo.github.io/notes/2022-03-01-jreleaser-graalvm-native-image/</link>
      <pubDate>Tue, 01 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/notes/2022-03-01-jreleaser-graalvm-native-image/</guid>
      <description>&lt;p&gt;Packaging and releasing Java applications (e.g. CLI) tend to be cumbersome, and the user-experience tended not to be the best as users have to download a valid version of JRE, etc.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Changing void returning type in Java methods breaks binary compatibility</title>
      <link>https://jeqo.github.io/notes/2022-02-16-java-void-binary-compatibility/</link>
      <pubDate>Wed, 16 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/notes/2022-02-16-java-void-binary-compatibility/</guid>
      <description>&lt;p&gt;While &lt;a href=&#34;https://cwiki.apache.org/confluence/display/KAFKA/KIP-820%3A+Extend+KStream+process+with+new+Processor+API&#34;&gt;proposing changes to Kafka Streams DSL&lt;/a&gt;, I propose changing the return type of one method from &lt;code&gt;void&lt;/code&gt; to &lt;code&gt;KStream&amp;lt;KOut, VOut&lt;/code&gt;.
I was under the (wrong) impression that this change wouldn&amp;rsquo;t affect users.
I was also not considering that applications might just drop a new library without recompiling their application.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Enable Certificate Revocation on Kafka clusters</title>
      <link>https://jeqo.github.io/notes/2022-02-09-kafka-ssl-crl/</link>
      <pubDate>Wed, 09 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/notes/2022-02-09-kafka-ssl-crl/</guid>
      <description>&lt;p&gt;Recently I got a question on how to manage revoked SSL certificates in Kafka clusters.
With a proper Public Key Infrastructure, a Certificate Revocation List (CRL) can be available for clients to validate if a certificate is still valid regardless of its time-to-live.
For instance, if a private key has been compromised, then a certificate can be revoked before it&amp;rsquo;s valid date.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Kafka Streams FK-join within the same KTable</title>
      <link>https://jeqo.github.io/notes/2022-01-29-kafka-streams-fk-join-same-table/</link>
      <pubDate>Sat, 29 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/notes/2022-01-29-kafka-streams-fk-join-same-table/</guid>
      <description>&lt;p&gt;KTable to KTable foreign-key joins is one of the coolest features in Kafka Streams.&lt;/p&gt;
&lt;p&gt;I was wondering whether this feature would handle FK-joins between values on the same table.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>The Value of Everything book</title>
      <link>https://jeqo.github.io/notes/the-value-of-everything-book/</link>
      <pubDate>Sat, 29 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/notes/the-value-of-everything-book/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://marianamazzucato.com/books/the-value-of-everything&#34;&gt;The Value of Everything&lt;/a&gt; by Mariana Mazzucato&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Kafka Streams abstracts access to multiple tasks state stores when reading</title>
      <link>https://jeqo.github.io/notes/2022-01-26-kafka-streams-iq-composite/</link>
      <pubDate>Wed, 26 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/notes/2022-01-26-kafka-streams-iq-composite/</guid>
      <description>&lt;p&gt;Kafka Streams applications could scale either horizontally (add more instances) or vertically (add more threads).
When scaled vertically, multiple tasks store multiple partitions locally.
An interesting question is whether Kafka Streams gives access when reading (i.e. &lt;a href=&#34;https://docs.confluent.io/platform/current/streams/developer-guide/interactive-queries.html&#34;&gt;Interactive Queries&lt;/a&gt;) to these stores, and how does it manage to abstract the access to different stores managed by multiple tasks.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>reload4j as drop-in replacement for log4j 1.x</title>
      <link>https://jeqo.github.io/notes/2022-01-25-reload4j/</link>
      <pubDate>Tue, 25 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/notes/2022-01-25-reload4j/</guid>
      <description>&lt;p&gt;TIL there is a drop-in replacement for log4j 1.x: &lt;a href=&#34;https://reload4j.qos.ch/&#34;&gt;Reload4j&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Ansible has a debug mode to pause and troubleshoot</title>
      <link>https://jeqo.github.io/notes/2022-01-21-ansible-debug/</link>
      <pubDate>Fri, 21 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/notes/2022-01-21-ansible-debug/</guid>
      <description>&lt;p&gt;I have been running Ansible for a while now.
My usual/naive way of debugging has always been adding a &lt;code&gt;debug&lt;/code&gt; module&lt;a href=&#34;https://docs.ansible.com/ansible/latest/collections/ansible/builtin/debug_module.html&#34;&gt;[1]&lt;/a&gt;, and get the execution running til that point.&lt;/p&gt;
&lt;p&gt;I figured that there are better ways to deal with this&lt;a href=&#34;https://docs.ansible.com/ansible/2.9/user_guide/playbooks_debugger.html#examples&#34;&gt;[2]&lt;/a&gt;.
By using the debug mode, tasks will stop when failing (by default) and you&amp;rsquo;ll be able to introspect into the task, variables, and context when things failed.
Even better, you&amp;rsquo;ll be able to re-execute if there was a transient error.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Changing Kafka Broker&#39;s rack</title>
      <link>https://jeqo.github.io/notes/2021-12-10-kafka-change-rack/</link>
      <pubDate>Fri, 10 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/notes/2021-12-10-kafka-change-rack/</guid>
      <description>&lt;p&gt;Kafka broker configuration includes a &lt;code&gt;rack&lt;/code&gt; label to define the location of the broker.
This is useful when placing replicas across the cluster to ensure replicas are spread across locations &lt;em&gt;as evenly as possible&lt;/em&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Kafka data loss scenarios</title>
      <link>https://jeqo.github.io/posts/2021-12-10-kafka-data-loss/</link>
      <pubDate>Fri, 10 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/posts/2021-12-10-kafka-data-loss/</guid>
      <description>Kafka topic partitions are replicated across brokers. Data loss happens when the brokers where replicas are located are unavailable or have fully failed. The worst scenario — and where is no much to do — is when all the brokers fail; then no remediation is possible. Replication allows to increase redundancy so this scenarios is less likely to happen.
The following scenarios show different trade-offs that could increase the risk of lossing data:</description>
    </item>
    
    <item>
      <title>Kafka Producer idempotency is enabled by default since 3.0</title>
      <link>https://jeqo.github.io/notes/2021-12-09-kafka-v3-idempotent-acks-all/</link>
      <pubDate>Thu, 09 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/notes/2021-12-09-kafka-v3-idempotent-acks-all/</guid>
      <description>Since Apache Kafka 3.0, Producers come with enable.idempotency=true which leads to acks=all, along with other changes enforced by idempotency.
This means by default Producers will be balanced between latency (no batching) and durability — different from previous versions where the main goal was to reduce latency even by risking durability with acks=1.</description>
    </item>
    
    <item>
      <title>Reducing `acks` doesn&#39;t help to reduce end-to-end latency</title>
      <link>https://jeqo.github.io/notes/2021-12-09-kafka-reducing-acks-and-latency/</link>
      <pubDate>Thu, 09 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/notes/2021-12-09-kafka-reducing-acks-and-latency/</guid>
      <description>&lt;p&gt;Kafka Producers enforce durability across replicas by setting &lt;code&gt;acks=all&lt;/code&gt; (&lt;a href=&#34;https://jeqo.github.io/til/kafka-v3-idea&#34;&gt;default since v3.0&lt;/a&gt;).
As enforcing this guarantee requires waiting for replicas to sync, this increases latency; and reducing it tends to give the impression that latency gets reduced overall.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Projects</title>
      <link>https://jeqo.github.io/projects/</link>
      <pubDate>Sat, 04 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/projects/</guid>
      <description>hashtag-outline &amp;nbsp;Open-source hashtag-outline &amp;nbsp;Apache Kafka https://github.com/apache/kafka
Main contributions:
Author of the following improvement proposals (KIP): KIP-122: https://cwiki.apache.org/confluence/display/KAFKA/KIP-122%3A+Add+Reset+Consumer+Group+Offsets+tooling (Adopted) KIP-171: https://cwiki.apache.org/confluence/display/KAFKA/KIP-171+-+Extend+Consumer+Group+Reset+Offset+for+Stream+Application (Adopted) KIP-244: https://cwiki.apache.org/confluence/display/KAFKA/KIP-244%3A+Add+Record+Header+support+to+Kafka+Streams+Processor+API (Adopted) KIP-634: https://cwiki.apache.org/confluence/display/KAFKA/KIP-634%3A+Complementary+support+for+headers+and+record+metadata+in+Kafka+Streams+DSL (Discarded) KIP-666: https://cwiki.apache.org/confluence/display/KAFKA/KIP-666%3A+Add+Instant-based+methods+to+ReadOnlySessionStore (Adopted) KIP-667: https://cwiki.apache.org/confluence/display/KAFKA/KIP-667%3A+Remove+deprecated+methods+from+ReadOnlyWindowStore (Adopted) KIP-820: https://cwiki.apache.org/confluence/display/KAFKA/KIP-820%3A+Extend+KStream+process+with+new+Processor+API (Adopted) KIP-821: https://cwiki.apache.org/confluence/display/KAFKA/KIP-821%3A+Connect+Transforms+support+for+nested+structures (Voting in progress) Helped with the implementation of: KIP-478: https://cwiki.apache.org/confluence/display/KAFKA/KIP-478+-+Strongly+typed+Processor+API https://issues.apache.org/jira/browse/KAFKA-8410 Proof-of-concepts:
Kafka CLIs: https://github.com/jeqo/kafka-cli Other minor PoCs: https://github.com/jeqo/poc-apache-kafka/ hashtag-outline &amp;nbsp;Zipkin https://github.com/openzipkin/zipkin
Main contributions:
Zipkin storage based on Kafka Streams: https://github.com/openzipkin-contrib/zipkin-storage-kafka Brave support for Kafka clients and streams: https://github.</description>
    </item>
    
    <item>
      <title>Cioran books</title>
      <link>https://jeqo.github.io/notes/cioran-books/</link>
      <pubDate>Fri, 03 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/notes/cioran-books/</guid>
      <description>&lt;p&gt;Including pictures from books:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The Trouble With Being Born&lt;/li&gt;
&lt;li&gt;A Short History Of Decay&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>Scale book</title>
      <link>https://jeqo.github.io/notes/scale-book/</link>
      <pubDate>Fri, 03 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/notes/scale-book/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://www.goodreads.com/book/show/31670196-scale&#34;&gt;Scale: The Universal Laws of Growth, Innovation, Sustainability, and the Pace of Life in Organisms, Cities, Economies, and Companies&lt;/a&gt; by Geoffrey B. West&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>The Age Of Surveillance Capitalism book</title>
      <link>https://jeqo.github.io/notes/the-age-of-surveillance-capitalism-book/</link>
      <pubDate>Fri, 03 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/notes/the-age-of-surveillance-capitalism-book/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://www.goodreads.com/book/show/26195941-the-age-of-surveillance-capitalism&#34;&gt;The Age Of Surveillance Capitalism&lt;/a&gt; by Shoshana Zuboff&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Use min.insync.replicas for fault-tolerance</title>
      <link>https://jeqo.github.io/notes/2021-12-02-kafka-min-isr/</link>
      <pubDate>Thu, 02 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/notes/2021-12-02-kafka-min-isr/</guid>
      <description>&lt;p&gt;Things to remember:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Topic replication factor is not enough to guarantee fault-tolerance. If &lt;code&gt;min.insync.replicas&lt;/code&gt; is not defined i.e. 1, then data could potentially be lost.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;acks=all&lt;/code&gt; will force replica leader to wait for &lt;em&gt;all&lt;/em&gt; brokers in the ISR, not only the &lt;code&gt;min.insync.replicas&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;If replicas available are equal to minimum ISR, then the topic partitions are at the edge of losing availability. If one broker becomes unavailable (e.g. restarting), then producers will fail to write data.&lt;/li&gt;
&lt;li&gt;Topic configuration is inherited from the server. If broker configuration changes, it affects the &lt;em&gt;existing&lt;/em&gt; topics. Keep the topic defaults, unless it needs to be different than broker default for easier maintenance.&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>About TILs</title>
      <link>https://jeqo.github.io/notes/2021-12-01-about-til/</link>
      <pubDate>Wed, 01 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/notes/2021-12-01-about-til/</guid>
      <description>Today I learned about Today-I-Learned posts from Simon Willison: https://til.simonwillison.net/ and found it super cool, so I decided to try out, let&amp;rsquo;s see how it goes.</description>
    </item>
    
    <item>
      <title>KIP-634: Complementary support for headers in Kafka Streams</title>
      <link>https://jeqo.github.io/drafts/kip-634/</link>
      <pubDate>Sun, 31 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/drafts/kip-634/</guid>
      <description>hashtag-outline &amp;nbsp;Motivation Headers are transiently passed over a Kafka Streams topology. To act on them, Processor API has to be used since (KIP-244).
Although current support is useful for instrumentations that need to access headers, it becomes cumbersome for users to access headers on common Kafka Streams DSL operations (e.g filtering based on header value) as requires using a Transformer/Processor implementation.
hashtag-outline &amp;nbsp;Related JIRA issues https://issues.apache.org/jira/browse/KAFKA-7718 hashtag-outline &amp;nbsp;Proposed Changes Include a new type, to map value and headers.</description>
    </item>
    
    <item>
      <title>KIP-617: Allow Kafka Streams State Stores to be iterated backwards</title>
      <link>https://jeqo.github.io/drafts/kip-617/</link>
      <pubDate>Mon, 18 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/drafts/kip-617/</guid>
      <description>hashtag-outline &amp;nbsp;Motivation Fetching range of records from Kafka Streams state stores comes with an iterator to traverse elements from oldest to newest, e.g ReadOnlyWindowStore#fetch(K key, long fromTime, long toTime) mentions:
For each key, the iterator guarantees ordering of windows, starting from the oldest/earliest&amp;quot;
Similar guarantees are provided on other fetch and range operations. But in the case of key ranges, there are some nuances regarding order:
The returned iterator must be safe from {@link java.</description>
    </item>
    
    <item>
      <title>About</title>
      <link>https://jeqo.github.io/about/</link>
      <pubDate>Sat, 11 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/about/</guid>
      <description>hashtag-outline &amp;nbsp;Jorge Esteban Quilcate Otoya Peruvian, husband, software engineer, and immigrant in Norway and the UK.
Enjoying my journey working on distributed systems.
Started to contribute to Open-Source projects since 2016, including Apache Kafka and Zipkin.
Current interests:
Log-based streaming platform (Apache Kafka), Stream processing (Kafka Streams), Distributed Tracing (OpenTracing), Metrics (Micrometer, Prometheus), Cluster Scheduling (Nomad, Kubernetes), Automation (Docker, Ansible) hashtag-outline &amp;nbsp;Open-Source contributions KIP-122: Add Reset Consumer Group Offsets tooling https://cwiki.</description>
    </item>
    
    <item>
      <title>Notes on Co-evolving Tracing and Fault Injection with Box of Pain</title>
      <link>https://jeqo.github.io/notes/2019-10-31-co-evolving-tracing-and-fault-injection/</link>
      <pubDate>Thu, 31 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/notes/2019-10-31-co-evolving-tracing-and-fault-injection/</guid>
      <description>This paper explores how related tracing and fault injection systems are, and if they should be part of the same thing.
The space of possible executions of a distributed system is exponential in the number of communicating precesses and the number of messages, [&amp;hellip;]
[&amp;hellip;] some of the most pernicious bugs in distributed programs involve mistakes on how programs handle partial failure of remote components.
In order to expose this failures, fault injection mechanisms are used to cause network partitions, or machine crashes.</description>
    </item>
    
    <item>
      <title>Making sense of Event-Driven Systems @ Oracle Code One 2019</title>
      <link>https://jeqo.github.io/talks/making-sense-event-driven-systems-codeone19/</link>
      <pubDate>Thu, 19 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/talks/making-sense-event-driven-systems-codeone19/</guid>
      <description>&lt;p&gt;Presented at &lt;a href=&#34;https://events.rainfocus.com/widget/oracle/oow19/catalogcodeone19?search=jorge&amp;amp;search.codeonetracks=15560568230440086BEm&#34;&gt;Oracle Code One 2019&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Making sense of Event-Driven Systems @ Kafka Summit 2019</title>
      <link>https://jeqo.github.io/talks/making-sense-event-driven-dataflows-kafkasummitnyc19/</link>
      <pubDate>Tue, 02 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/talks/making-sense-event-driven-dataflows-kafkasummitnyc19/</guid>
      <description>&lt;p&gt;Presented at &lt;a href=&#34;https://kafka-summit.org/sessions/tracing-kafka-based-applications-making-sense-event-driven-dataflows/&#34;&gt;Kafka Summit NYC 2019&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>The Importance of Distributed Tracing for Apache Kafka Based Applications</title>
      <link>https://jeqo.github.io/posts/2019-03-26-importance-of-distributed-tracing-for-apache-kafka-based-applications/</link>
      <pubDate>Tue, 26 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/posts/2019-03-26-importance-of-distributed-tracing-for-apache-kafka-based-applications/</guid>
      <description>Originally posted in Confluent Blog
Apache Kafka® based applications stand out for their ability to decouple producers and consumers using an event log as an intermediate layer.
One result of this is that producers and consumers don’t know about each other, as there is no direct communication between them.
This enables choreographed service collaborations, where many components can subscribe to events stored in the event log and react to them asynchronously.</description>
    </item>
    
    <item>
      <title>The Importance of Observability for Kafka-based applications with Zipkin @ Oslo Apache Kafka Meetup</title>
      <link>https://jeqo.github.io/talks/the-importance-of-observability-kafkausergroupnorway18/</link>
      <pubDate>Mon, 10 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/talks/the-importance-of-observability-kafkausergroupnorway18/</guid>
      <description>&lt;p&gt;Presented at &lt;a href=&#34;https://www.meetup.com/en-AU/Oslo-Kafka/events/254039906/&#34;&gt;Oslo Apache Kafka Meetup&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Notes on Kafka, Samza and the Unix Philosophy of Distributed Data</title>
      <link>https://jeqo.github.io/notes/2018-07-27-kafka-samza-and-the-unix-philosophy-of-distributed-data/</link>
      <pubDate>Fri, 27 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/notes/2018-07-27-kafka-samza-and-the-unix-philosophy-of-distributed-data/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Data on the Outside vs Data on the Inside</title>
      <link>https://jeqo.github.io/notes/2018-01-08-data-on-the-outside-vs-data-on-the-inside/</link>
      <pubDate>Mon, 08 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/notes/2018-01-08-data-on-the-outside-vs-data-on-the-inside/</guid>
      <description>&lt;p&gt;I found this paper as relevant and accurate today as it was in 2005, when it was published.
It is fascinating how even 12 years later and with new technologies in vogue,
same concepts keep applying.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Distributed Tracing with OpenTracing @ NoSlidesConf 2017</title>
      <link>https://jeqo.github.io/talks/distributed-tracing-with-opentracing-noslides18/</link>
      <pubDate>Sat, 25 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/talks/distributed-tracing-with-opentracing-noslides18/</guid>
      <description>&lt;p&gt;Presented at &lt;a href=&#34;http://www.noslidesconf.net/&#34;&gt;NoSlidesConf 2017&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Tracing Kafka applications</title>
      <link>https://jeqo.github.io/posts/2017-09-28-kafka-opentracing/</link>
      <pubDate>Thu, 28 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/posts/2017-09-28-kafka-opentracing/</guid>
      <description>for a more updated version, check https://jeqo.github.io/posts/2019-03-26-importance-of-distributed-tracing-for-apache-kafka-based-applications/
Tracing is one of the hardest time in integration or microservice development: knowing how a request impact your different components, and if your components have behave as expected.
This could be fairly easy if we have monolith where we have one database and with some queries or checking one log file you can validate everything went well.
Once you introduce distributed components and asynchronous communication this starts to get more complex and tedious.</description>
    </item>
    
    <item>
      <title>From Messaging to Logs with Apache Kafka @ OUGN 2017</title>
      <link>https://jeqo.github.io/talks/from-messaging-to-logs-ougn17/</link>
      <pubDate>Fri, 10 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/talks/from-messaging-to-logs-ougn17/</guid>
      <description>&lt;p&gt;Presented at &lt;a href=&#34;http://ougn.no/varseminar-2017/&#34;&gt;OUGN 2017&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Scaling WebLogic, the Kubernetes way @ OUGN 2017</title>
      <link>https://jeqo.github.io/talks/scale-wls-the-k8s-way-ougn-17/</link>
      <pubDate>Thu, 09 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/talks/scale-wls-the-k8s-way-ougn-17/</guid>
      <description>&lt;p&gt;Presented at &lt;a href=&#34;http://ougn.no/varseminar-2017/&#34;&gt;OUGN 2017&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Rewind Kafka Consumer Offsets</title>
      <link>https://jeqo.github.io/posts/2017-01-31-kafka-rewind-consumers-offset/</link>
      <pubDate>Tue, 31 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/posts/2017-01-31-kafka-rewind-consumers-offset/</guid>
      <description>&lt;p&gt;One of the most important features from &lt;em&gt;Apache Kafka&lt;/em&gt; is how it manages
Multiple Consumers. Each &lt;code&gt;consumer group&lt;/code&gt; has a current &lt;code&gt;offset&lt;/code&gt;, that
determine at what point in a &lt;code&gt;topic&lt;/code&gt; this &lt;code&gt;consumer group&lt;/code&gt; has consume
messages. So, each &lt;code&gt;consumer group&lt;/code&gt; can manage its &lt;code&gt;offset&lt;/code&gt; independently,
by &lt;code&gt;partition&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;This offers the possibility to rollback in time and reprocess messages from
the beginning of a &lt;code&gt;topic&lt;/code&gt; and regenerate the current status of the system.&lt;/p&gt;
&lt;p&gt;But how to do it (programmatically)?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Scaling Kafka with Docker Containers</title>
      <link>https://jeqo.github.io/posts/2017-01-15-scale-kafka-containers/</link>
      <pubDate>Sun, 15 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/posts/2017-01-15-scale-kafka-containers/</guid>
      <description>&lt;p&gt;In this post I will show how to use Docker containers to create and scale
a Kafka cluster, and also how to create, scale and move &lt;code&gt;topics&lt;/code&gt; inside
the cluster.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Speed up your Oracle Database provisioning with Docker and Ansible</title>
      <link>https://jeqo.github.io/posts/2016-05-26-speed-up-oracle-database-provisioning-ansible-docker/</link>
      <pubDate>Thu, 26 May 2016 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/posts/2016-05-26-speed-up-oracle-database-provisioning-ansible-docker/</guid>
      <description>&lt;p&gt;Warming up before &lt;a href=&#34;http://www.amis-conference.com/Program&#34;&gt;AMIS 25th Conference&lt;/a&gt;
event where I will be presenting with my friend
and colleague Arturo Viveros (@gugalnikov)
&lt;a href=&#34;http://www.amis-conference.com/Session-Catalog#session1168&#34;&gt;about Oracle SOA Suite provisioning&lt;/a&gt;,
I want to share some practices that help us to provide Oracle Database instances
between developers and improve our productivity.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Lightning Quick Provisioning and DevOps for Oracle SOA Suite 12c @ AMIS 25</title>
      <link>https://jeqo.github.io/talks/lighning-provisioning-oracle-soa-suite-amis25/</link>
      <pubDate>Mon, 02 May 2016 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/talks/lighning-provisioning-oracle-soa-suite-amis25/</guid>
      <description>&lt;p&gt;Presented at &lt;a href=&#34;http://www.amis.nl/en/events-eng/jubileumconferentie/&#34;&gt;AMIS25 2016&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Ansible - an agentless provisioning</title>
      <link>https://jeqo.github.io/posts/2016-03-30-ansible-agentless-provisioning/</link>
      <pubDate>Wed, 30 Mar 2016 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/posts/2016-03-30-ansible-agentless-provisioning/</guid>
      <description>&lt;p&gt;Ansible is an automation tool that is recognized for be simple and
powerful at the same time. From my experience, I can say this is mainly
because of its scripting language: YAML, and its agentless architecture.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Oracle SOA Suite 12c Docker Image</title>
      <link>https://jeqo.github.io/posts/2015-09-04-oracle-soa-12c-packer-docker-hub/</link>
      <pubDate>Fri, 04 Sep 2015 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/posts/2015-09-04-oracle-soa-12c-packer-docker-hub/</guid>
      <description>&lt;p&gt;After find some limitations on building SOA Docker image using Dockerfile
(as volume access, default size image) I researched on how to improve
building process and I found &lt;a href=&#34;https://packer.io/&#34;&gt;Packer&lt;/a&gt;
(from the same guy that creates Vagrant).&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Integrate Java EE 7 and Kafka using Avro and RxJava</title>
      <link>https://jeqo.github.io/posts/2015-07-31-java-ee-rxjava-kafka-avro/</link>
      <pubDate>Fri, 31 Jul 2015 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/posts/2015-07-31-java-ee-rxjava-kafka-avro/</guid>
      <description>&lt;p&gt;I decided to implement a naive integration between Java EE applications and
RxJava/Kafka/Avro, to publish and subscribe to events.&lt;/p&gt;
&lt;p&gt;You can go directly to that &lt;a href=&#34;https://github.com/jeqo/java-ee-rxjava-kafka-avro&#34;&gt;code&lt;/a&gt;, or check my approach:&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Oracle Fusion Middleware Chef Cookbook - New Release!</title>
      <link>https://jeqo.github.io/posts/2015-07-21-chef-cookbook-oracle-fmw-0-2-0/</link>
      <pubDate>Tue, 21 Jul 2015 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/posts/2015-07-21-chef-cookbook-oracle-fmw-0-2-0/</guid>
      <description>&lt;p&gt;Yesterday, I released a new version (0.2.0) of my Oracle Fusion Middleware Cookbook
hosted on &lt;a href=&#34;https://supermarket.chef.io/cookbooks/oracle-fmw&#34;&gt;Chef Supermarket&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>What is Adaptive Case Management? @ OUGN 15</title>
      <link>https://jeqo.github.io/talks/what-is-adaptive-case-management-ougn15/</link>
      <pubDate>Sat, 02 May 2015 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/talks/what-is-adaptive-case-management-ougn15/</guid>
      <description>&lt;p&gt;Presented at &lt;a href=&#34;http://www.amis.nl/en/events-eng/jubileumconferentie/&#34;&gt;AMIS25 2016&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Docker image for Oracle SOA Suite 12c</title>
      <link>https://jeqo.github.io/posts/2015-04-01-docker-image-oracle-soa/</link>
      <pubDate>Wed, 01 Apr 2015 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/posts/2015-04-01-docker-image-oracle-soa/</guid>
      <description>&lt;p&gt;Cool news came from Oracle a couple of weeks ago: &lt;a href=&#34;https://blogs.oracle.com/WebLogicServer/entry/oracle_weblogic_server_now_running&#34;&gt;Oracle WebLogic Server is now supported on Docker!&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Running Oracle BPM 12c on AWS using Vagrant and Chef</title>
      <link>https://jeqo.github.io/posts/2014-12-11-run-bpm-12c-aws/</link>
      <pubDate>Thu, 11 Dec 2014 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/posts/2014-12-11-run-bpm-12c-aws/</guid>
      <description>&lt;p&gt;In this post, I will show how to create an AWS EC2 Instance with an Oracle BPM 12c Quickstart Domain created. And I will use previous post for related tasks.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Chef Cookbook for Oracle Fusion Middleware 12c</title>
      <link>https://jeqo.github.io/posts/2014-12-09-chef-cookbook-oracle-fmw-12c/</link>
      <pubDate>Tue, 09 Dec 2014 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/posts/2014-12-09-chef-cookbook-oracle-fmw-12c/</guid>
      <description>&lt;p&gt;Provisioning tools have change the way we create software environments: How much time we spend installing OS, databases, configuring platforms, applications? Now you can translate this steps into code, getting the software development benefits and challenges into infrastructure: versioning, reuse, continuous improvement.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Create a NFS instance on AWS using Vagrant and Chef</title>
      <link>https://jeqo.github.io/posts/2014-11-30-create-nfs-instance-aws/</link>
      <pubDate>Sun, 30 Nov 2014 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/posts/2014-11-30-create-nfs-instance-aws/</guid>
      <description>&lt;p&gt;I was creating AWS EC2 instances to install Oracle Fusion Middleware products, and I found an issue: How to download Oracle&amp;rsquo;s installers if I want to use installers on several instances? This could consume a lot of network bandwith and I want to make this process repeatable, so I don&amp;rsquo;t want to wait 1 hour each installation only downloading files.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Book Review - Applied SOA Patterns on the Oracle Platform</title>
      <link>https://jeqo.github.io/posts/2014-11-28-review-soa-patterns-oracle-platform/</link>
      <pubDate>Fri, 28 Nov 2014 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/posts/2014-11-28-review-soa-patterns-oracle-platform/</guid>
      <description>&lt;p&gt;I&amp;rsquo;ve had the opportunity to present a review of this book &lt;a href=&#34;https://www.packtpub.com/application-development/applied-soa-patterns-oracle-platform&#34;&gt;Applied SOA Patterns on the Oracle Platform&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Vagrant and Chef Quickstart</title>
      <link>https://jeqo.github.io/posts/2014-11-26-vagrant-quickstart/</link>
      <pubDate>Wed, 26 Nov 2014 00:00:00 +0000</pubDate>
      
      <guid>https://jeqo.github.io/posts/2014-11-26-vagrant-quickstart/</guid>
      <description>&lt;p&gt;I have some months working with Vagrant and I think it&amp;rsquo;s owesome! Integration with almost all kind of virtualization platforms: VirtalBox, VMware, Docker, AWS EC2, Hyper-V and so on. Also it&amp;rsquo;s able to use differente Provisioners: Chef, Puppet, bash, Docker, Ansible. I really like it.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
